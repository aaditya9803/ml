{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaditya9803/ml/blob/main/Condition_monitoring_of_hydraulic_systems_(different_approach).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf1uQ4MalsjS"
      },
      "source": [
        "\n",
        "## Importing files from Google drive\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o9hm423Wy4A8",
        "outputId": "0aa14980-3e58-4a6c-8619-02a617685885"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading CE.txt...\n",
            "Downloading CP.txt...\n",
            "Downloading EPS1.txt...\n",
            "Downloading FS1.txt...\n",
            "Downloading FS2.txt...\n",
            "Downloading PS1.txt...\n",
            "Downloading PS2.txt...\n",
            "Downloading PS3.txt...\n",
            "Downloading PS4.txt...\n",
            "Downloading PS5.txt...\n",
            "Downloading PS6.txt...\n",
            "Downloading SE.txt...\n",
            "Downloading TS1.txt...\n",
            "Downloading TS2.txt...\n",
            "Downloading TS3.txt...\n",
            "Downloading TS4.txt...\n",
            "Downloading VS1.txt...\n",
            "Downloading profile.txt...\n",
            "All files downloaded (if found).\n"
          ]
        }
      ],
      "source": [
        "!pip install -U -q PyDrive\n",
        "!pip install -U -q dask\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# List of file names.\n",
        "file_names = ['CE.txt', 'CP.txt', 'EPS1.txt', 'FS1.txt', 'FS2.txt',\n",
        "              'PS1.txt', 'PS2.txt', 'PS3.txt', 'PS4.txt', 'PS5.txt',\n",
        "              'PS6.txt', 'SE.txt', 'TS1.txt', 'TS2.txt', 'TS3.txt',\n",
        "              'TS4.txt', 'VS1.txt','profile.txt']\n",
        "\n",
        "# Get the ID of the current folder (where the notebook is located).\n",
        "# Assuming the notebook is in \"My Drive/Colab Notebooks\" or similar\n",
        "# by default.\n",
        "# Alternatively, you can get a specific folder ID or use a method to find your folder\n",
        "current_folder_id = '1_lAGYQ1p9oY9_OM0LMAL3gbKGBY7HuM5' # Replace with your specific folder ID if needed\n",
        "\n",
        "\n",
        "# Iterate through the file names and download each file.\n",
        "for file_name in file_names:\n",
        "    # List files in the current folder.\n",
        "    file_list = drive.ListFile({'q': \"'{}' in parents and trashed=false\".format(current_folder_id)}).GetList()\n",
        "\n",
        "    # Find the file with the matching name.\n",
        "    file_to_download = next((file for file in file_list if file['title'] == file_name), None)\n",
        "\n",
        "    if file_to_download:\n",
        "        # Download the file.\n",
        "        print(f\"Downloading {file_name}...\")\n",
        "        file_to_download.GetContentFile(file_name)  # Downloads to Colab environment\n",
        "    else:\n",
        "        print(f\"File {file_name} not found in the folder.\")\n",
        "\n",
        "print(\"All files downloaded (if found).\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVaCM3Vol89l"
      },
      "source": [
        "# Importing python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "EGXTBswBzr0R"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime as dt\n",
        "import seaborn as sns\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import xgboost as xgb\n",
        "import os\n",
        "from sklearn.model_selection import KFold, cross_val_predict, cross_val_score\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import confusion_matrix, classification_report, f1_score, precision_score, accuracy_score\n",
        "import pickle\n",
        "from google.colab import files\n",
        "import gc\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from sklearn.utils.class_weight import compute_class_weight\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nLCnaftgmRbm"
      },
      "source": [
        "## Features and Targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "zGQA3CcY1cC_"
      },
      "outputs": [],
      "source": [
        "def read_file(filename):\n",
        "    return pd.read_csv((filename), sep='\\t', header=None)\n",
        "\n",
        "pressureFile1 = read_file(filename='PS1.txt')\n",
        "pressureFile2 = read_file(filename='PS2.txt')\n",
        "pressureFile3 = read_file(filename='PS3.txt')\n",
        "pressureFile4 = read_file(filename='PS4.txt')\n",
        "pressureFile5 = read_file(filename='PS5.txt')\n",
        "pressureFile6 = read_file(filename='PS6.txt')\n",
        "\n",
        "\n",
        "volumeFlow1 = read_file(filename='FS1.txt')\n",
        "volumeFlow2 = read_file(filename='FS2.txt')\n",
        "\n",
        "\n",
        "temperature1 = read_file(filename='TS1.txt')\n",
        "temperature2 = read_file(filename='TS2.txt')\n",
        "temperature3 = read_file(filename='TS3.txt')\n",
        "temperature4 = read_file(filename='TS4.txt')\n",
        "\n",
        "pump1 = read_file(filename='EPS1.txt')\n",
        "vibration1 = read_file(filename='VS1.txt')\n",
        "coolingE1 = read_file(filename='CE.txt')\n",
        "coolingP1 = read_file(filename='CP.txt')\n",
        "effFactor1 = read_file(filename='SE.txt')\n",
        "\n",
        "profile = read_file(filename='profile.txt')\n",
        "\n",
        "\n",
        "# for the targets\n",
        "\n",
        "y_coolerCondition = pd.DataFrame(profile.iloc[:, 0])\n",
        "y_valveCondition = pd.DataFrame(profile.iloc[:, 1])\n",
        "y_pumpLeak = pd.DataFrame(profile.iloc[:, 2])\n",
        "y_hydraulicAcc = pd.DataFrame(profile.iloc[:, 3])\n",
        "y_stableFlag = pd.DataFrame(profile.iloc[:, 4])\n",
        "\n",
        "y_pumpLeak = pd.Series(y_pumpLeak.values.flatten(), name='pumpLeak')\n",
        "y_coolerCondition = pd.Series(y_coolerCondition.values.flatten(), name='coolerCondition')\n",
        "y_valveCondition = pd.Series(y_valveCondition.values.flatten(), name='valveCondition')\n",
        "y_hydraulicAcc = pd.Series(y_hydraulicAcc.values.flatten(), name='hydraulicAcc')\n",
        "y_stableFlag = pd.Series(y_stableFlag.values.flatten(), name='stableFlag')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3iMr5A7SBlia",
        "outputId": "533aa5d8-ff4c-450f-8b13-97fe9da389c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2205, 6000)"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "pressureFile1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPYhuotfmjn4"
      },
      "source": [
        "##Functions to Upsample and Downsample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "VpXG9s8blnpO"
      },
      "outputs": [],
      "source": [
        "#converts 100hz to 10hz\n",
        "def mean_conversion_100hz(df, chunk_size=10, prefix=''):\n",
        "    num_chunks = df.shape[1] // chunk_size\n",
        "    columns = [f'{prefix}_{i}' for i in range(num_chunks)]\n",
        "    df_mean_chunks = pd.DataFrame(index=df.index, columns=columns)\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        mean_chunks = row.values.reshape(-1, chunk_size).mean(axis=1)\n",
        "        df_mean_chunks.loc[index] = mean_chunks\n",
        "\n",
        "    return df_mean_chunks\n",
        "\n",
        "\n",
        "#converts 100hz to 1z\n",
        "def mean_conversion_1hz(df, chunk_size=100, prefix=''):\n",
        "    num_chunks = df.shape[1] // chunk_size\n",
        "    columns = [f'{prefix}_{i}' for i in range(num_chunks)]\n",
        "    df_mean_chunks = pd.DataFrame(index=df.index, columns=columns)\n",
        "\n",
        "    for index, row in df.iterrows():\n",
        "        mean_chunks = row.values.reshape(-1, chunk_size).mean(axis=1)\n",
        "        df_mean_chunks.loc[index] = mean_chunks\n",
        "\n",
        "    return df_mean_chunks\n",
        "    expanded_row = np.repeat(row.values, repeat_count)\n",
        "    all_expanded_rows.append(pd.Series(expanded_row))\n",
        "    df_expanded = pd.concat(all_expanded_rows, ignore_index=True)  # Concatenate all rows at once\n",
        "\n",
        "    return df_expanded\n",
        "\n",
        "#For mean of the row (mean of the cycle)\n",
        "def mean_conversion(df):\n",
        "    df1 = pd.DataFrame()\n",
        "    df1['mean'] = df.mean(axis=1)\n",
        "    return df1\n",
        "\n",
        "#For Upsampling\n",
        "def repeat_values(df, repeat_count=10):\n",
        "    # For single-column DataFrames, repeat values horizontally\n",
        "    if df.shape[1] == 1:  # Check if single-column\n",
        "        df_expanded = pd.DataFrame(\n",
        "            np.repeat(df.values, repeat_count, axis=1), index=df.index\n",
        "        )\n",
        "    else:\n",
        "        # Otherwise, repeat each value in a row horizontally for all columns\n",
        "        df_expanded = df.apply(lambda row: np.tile(row.values, repeat_count), axis=1)\n",
        "        df_expanded = pd.DataFrame(df_expanded.tolist(), index=df.index)\n",
        "\n",
        "    return df_expanded\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Co23-aDCWDtg"
      },
      "source": [
        "# Functions to Train Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q6-iEzNBQj9N"
      },
      "source": [
        "## Using XGB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "jWwlX5k8_vkW"
      },
      "outputs": [],
      "source": [
        "def xgb_(X, y, num_folds=5):\n",
        "\n",
        "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=24)\n",
        "\n",
        "    f1_scores = []\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "\n",
        "    for fold_idx, (train_idx, test_idx) in enumerate(kf.split(X)):\n",
        "        print(f\"Fold {fold_idx + 1}:\")\n",
        "\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        # Initialize and train the XGBoost model with regularization\n",
        "        xgb1 = xgb.XGBClassifier(\n",
        "            objective=\"binary:logistic\",\n",
        "            random_state=42,\n",
        "            alpha=2.0,\n",
        "            reg_lambda=2.0,\n",
        "            max_depth=4,\n",
        "            min_child_weight=10,\n",
        "            subsample=0.8,\n",
        "            colsample_bytree=0.8\n",
        "        )\n",
        "\n",
        "        # Fit the model\n",
        "        xgb1.fit(X_train.to_numpy(), y_train.to_numpy().ravel())\n",
        "\n",
        "        # Make predictions\n",
        "        y_pred = xgb1.predict(X_test.to_numpy())\n",
        "\n",
        "        # Ensure y_test is 1D for comparison\n",
        "        y_test = y_test.to_numpy().ravel().astype(int)\n",
        "        y_pred = y_pred.astype(int)\n",
        "\n",
        "        # Calculate and store F1-score for this fold\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "        f1_scores.append(f1)\n",
        "\n",
        "        # Calculate and store accuracy and precision for this fold\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        accuracies.append(accuracy)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted')\n",
        "        precisions.append(precision)\n",
        "\n",
        "        print(classification_report(y_test, y_pred))\n",
        "        print(f\"Fold {fold_idx + 1} F1-score: {f1:.4f}\")\n",
        "        print(f\"Fold {fold_idx + 1} Accuracy: {accuracy:.4f}\")\n",
        "        print(f\"Fold {fold_idx + 1} Precision: {precision:.4f}\")\n",
        "\n",
        "        # Calculate and print confusion matrix\n",
        "        cm = confusion_matrix(y_test, y_pred)\n",
        "        print(\"Confusion Matrix:\")\n",
        "        print(cm)\n",
        "\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "    # Calculate and print average metrics across all folds\n",
        "    avg_f1 = np.mean(f1_scores)\n",
        "    avg_accuracy = np.mean(accuracies)\n",
        "    avg_precision = np.mean(precisions)\n",
        "\n",
        "    print(f\"Average F1-score across {num_folds} folds: {avg_f1:.4f}\")\n",
        "    print(f\"Average Accuracy across {num_folds} folds: {avg_accuracy:.4f}\")\n",
        "    print(f\"Average Precision across {num_folds} folds: {avg_precision:.4f}\")\n",
        "\n",
        "    # Final model: Train on the entire dataset\n",
        "    print(\"Training final model on the entire dataset...\")\n",
        "    X_train_final, X_test_final, y_train_final, y_test_final = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Final model with regularization\n",
        "    final_model = xgb.XGBClassifier(\n",
        "        objective=\"binary:logistic\",\n",
        "        random_state=42,\n",
        "        alpha=1.0,\n",
        "        reg_lambda=1.0,\n",
        "        max_depth=5,\n",
        "        min_child_weight=10,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8\n",
        "    )\n",
        "\n",
        "    # Train on the entire dataset\n",
        "    final_model.fit(X_train_final.to_numpy(), y_train_final.to_numpy().ravel())\n",
        "\n",
        "    # Evaluate the final model on the test set\n",
        "    y_pred_final = final_model.predict(X_test_final.to_numpy())\n",
        "\n",
        "    # Calculate accuracy, precision, confusion matrix for final model\n",
        "    final_accuracy = accuracy_score(y_test_final, y_pred_final)\n",
        "    final_precision = precision_score(y_test_final, y_pred_final, average='weighted')\n",
        "    final_cm = confusion_matrix(y_test_final, y_pred_final)\n",
        "\n",
        "    print(f\"Final Model Accuracy: {final_accuracy:.4f}\")\n",
        "    print(f\"Final Model Precision: {final_precision:.4f}\")\n",
        "    print(\"Final Model Confusion Matrix:\")\n",
        "    print(final_cm)\n",
        "\n",
        "    # Save the final model\n",
        "    with open('XGB_final_model.pkl', 'wb') as f:\n",
        "        pickle.dump(final_model, f)\n",
        "    files.download('XGB_final_model.pkl')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NUshBnzxUbzy"
      },
      "source": [
        "## Using SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "iyZUCc-lBnFJ"
      },
      "outputs": [],
      "source": [
        "def svm(X, y):\n",
        "    # Split the data into training and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "    # Create the SVM model\n",
        "    model = SVC(kernel='rbf', C=1, gamma='auto')\n",
        "\n",
        "    # Perform cross-validation with predictions to calculate precision and accuracy\n",
        "    y_pred_cv = cross_val_predict(model, X_train, y_train, cv=5)\n",
        "\n",
        "    # Calculate precision for each fold\n",
        "    precisions = []\n",
        "    accuracies = []\n",
        "    for fold in range(5):\n",
        "        y_true_fold = y_train[fold::5]\n",
        "        y_pred_fold = y_pred_cv[fold::5]\n",
        "        precision = precision_score(y_true_fold, y_pred_fold, average='binary')\n",
        "        precisions.append(precision)\n",
        "\n",
        "        #accuracy for each fold\n",
        "        accuracy = accuracy_score(y_true_fold, y_pred_fold)\n",
        "        accuracies.append(accuracy)\n",
        "\n",
        "    # average precision, average accuracy\n",
        "    print(\"Precision scores for each fold:\", precisions)\n",
        "    print(\"Average precision:\", np.mean(precisions))\n",
        "    print(\"Average accuracy:\", np.mean(accuracies))\n",
        "\n",
        "    # Compute and print confusion matrix for cross-validation\n",
        "    cm = confusion_matrix(y_train, y_pred_cv)\n",
        "    print(\"Confusion matrix for training set:\\n\", cm)\n",
        "\n",
        "    # Train the model on the entire training set\n",
        "    model.fit(X_train, y_train)\n",
        "\n",
        "    # Make predictions on the test set and evaluate\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # Evaluate on the test set\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='binary')\n",
        "    cm_test = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    print(f\"Test set accuracy: {accuracy}\")\n",
        "    print(f\"Test set precision: {precision}\")\n",
        "    print(\"Test set confusion matrix:\\n\", cm_test)\n",
        "\n",
        "    with open('svm_model.pkl', 'wb') as f:\n",
        "        pickle.dump(model, f)\n",
        "\n",
        "    files.download('svm_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75ZhKb_oUpxw"
      },
      "source": [
        "## Using Random forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "DIvSnWrMuUXY"
      },
      "outputs": [],
      "source": [
        "def randomforest(X, y, num_folds=5):\n",
        "    #Split into train and test sets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    #cross-validation on the training set\n",
        "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=24)\n",
        "\n",
        "    precisions = []\n",
        "    accuracies = []\n",
        "\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train)):\n",
        "        X_train_fold, X_val_fold = X_train.iloc[train_idx], X_train.iloc[val_idx]\n",
        "        y_train_fold, y_val_fold = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
        "\n",
        "        rf_model = RandomForestClassifier(\n",
        "            n_estimators=100,\n",
        "            random_state=42,\n",
        "            max_depth=8,\n",
        "            min_samples_leaf=3,\n",
        "            max_features=\"sqrt\"\n",
        "        )\n",
        "        rf_model.fit(X_train_fold, y_train_fold)\n",
        "        y_pred_val = rf_model.predict(X_val_fold)\n",
        "\n",
        "        #precision and accuracy for each fold\n",
        "        fold_precision = precision_score(y_val_fold, y_pred_val, average='binary')\n",
        "        fold_accuracy = accuracy_score(y_val_fold, y_pred_val)\n",
        "\n",
        "        precisions.append(fold_precision)\n",
        "        accuracies.append(fold_accuracy)\n",
        "\n",
        "        print(f\"Fold {fold_idx + 1} Classification Report:\")\n",
        "        print(classification_report(y_val_fold, y_pred_val))\n",
        "\n",
        "    #Print average precision and accuracy for cross-validation\n",
        "    print(f\"Average Precision across {num_folds} folds: {np.mean(precisions)}\")\n",
        "    print(f\"Average Accuracy across {num_folds} folds: {np.mean(accuracies)}\")\n",
        "\n",
        "    #Train the final model on the full training data\n",
        "    final_rf_model = RandomForestClassifier(\n",
        "        n_estimators=100,\n",
        "        random_state=42,\n",
        "        max_depth=8,  # Use the same tuned parameters\n",
        "        min_samples_leaf=3,\n",
        "        max_features=\"sqrt\"\n",
        "    )\n",
        "    final_rf_model.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the final model on the test set\n",
        "    y_test_pred = final_rf_model.predict(X_test)\n",
        "    print(\"Final Test Set Evaluation:\")\n",
        "    print(classification_report(y_test, y_test_pred))\n",
        "\n",
        "    # Calculate accuracy and precision for the final model\n",
        "    final_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "    final_precision = precision_score(y_test, y_test_pred, average='binary')  # Use 'binary' or 'macro' based on the task\n",
        "\n",
        "    print(f\"Final Model Accuracy: {final_accuracy}\")\n",
        "    print(f\"Final Model Precision: {final_precision}\")\n",
        "\n",
        "    # Print confusion matrix for the test set\n",
        "    cm_test = confusion_matrix(y_test, y_test_pred)\n",
        "    print(\"Confusion Matrix - Final Model (Test Set):\")\n",
        "    print(cm_test)\n",
        "\n",
        "    with open('rf_model.pkl', 'wb') as f:\n",
        "      pickle.dump(final_rf_model, f)\n",
        "\n",
        "    files.download('rf_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAqf7PGQU2bu"
      },
      "source": [
        "## Using Neural Networks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "WSEvQgOTH-8d"
      },
      "outputs": [],
      "source": [
        "def neuralnetwork(X, y, num_folds=5, patience=5, test_size=0.2):\n",
        "    # Step 1: Split data into train and test sets\n",
        "    X_train_full, X_test, y_train_full, y_test = train_test_split(X, y, test_size=test_size, random_state=42)\n",
        "\n",
        "    # Convert DataFrames to numpy arrays if they are pandas DataFrames\n",
        "    X_train_full = X_train_full.values\n",
        "    X_test = X_test.values\n",
        "    y_train_full = y_train_full.values\n",
        "    y_test = y_test.values\n",
        "\n",
        "    # Initialize lists to store accuracy and precision for each fold\n",
        "    accuracies = []\n",
        "    precisions = []\n",
        "\n",
        "    # Step 2: Perform cross-validation on the training set\n",
        "    kf = KFold(n_splits=num_folds, shuffle=True, random_state=24)\n",
        "    models = []  # List to store models from each fold\n",
        "\n",
        "    for fold_idx, (train_idx, val_idx) in enumerate(kf.split(X_train_full)):\n",
        "        X_train, X_val = X_train_full[train_idx], X_train_full[val_idx]\n",
        "        y_train, y_val = y_train_full[train_idx], y_train_full[val_idx]\n",
        "\n",
        "        # Flatten y_train to ensure it's a 1D array\n",
        "        y_train = y_train.flatten()\n",
        "        y_val = y_val.flatten()\n",
        "\n",
        "        # Build the model\n",
        "        model = keras.Sequential([\n",
        "            keras.layers.Input(shape=(X_train.shape[1],)),\n",
        "            keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=0.01, l2=0.01)),\n",
        "            keras.layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=0.01, l2=0.01)),\n",
        "            keras.layers.Dense(3, activation='softmax')  # 3 outputs for 3 classes (multiclass classification)\n",
        "        ])\n",
        "        model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "        # EarlyStopping callback\n",
        "        early_stopping = EarlyStopping(\n",
        "            monitor='val_loss',\n",
        "            patience=patience,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "\n",
        "        # Train the model\n",
        "        model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
        "\n",
        "        # Append the trained model to the list\n",
        "        models.append(model)\n",
        "\n",
        "        # Evaluate on the validation set\n",
        "        y_val_pred = model.predict(X_val)\n",
        "        y_val_pred_classes = np.argmax(y_val_pred, axis=1)  # Get the predicted class\n",
        "\n",
        "        # Compute accuracy and precision for this fold\n",
        "        fold_accuracy = accuracy_score(y_val, y_val_pred_classes)\n",
        "        fold_precision = precision_score(y_val, y_val_pred_classes, average='weighted', zero_division=0)\n",
        "\n",
        "        # Store the accuracy and precision for this fold\n",
        "        accuracies.append(fold_accuracy)\n",
        "        precisions.append(fold_precision)\n",
        "\n",
        "        # Metrics for each fold\n",
        "        print(f\"Fold {fold_idx + 1}:\")\n",
        "        print(\"Validation Confusion Matrix:\")\n",
        "        print(confusion_matrix(y_val, y_val_pred_classes))\n",
        "        print(classification_report(y_val, y_val_pred_classes))\n",
        "\n",
        "    # Print average accuracy and precision across all folds\n",
        "    print(f\"Average Accuracy across all folds: {np.mean(accuracies):.4f}\")\n",
        "    print(f\"Average Precision across all folds: {np.mean(precisions):.4f}\")\n",
        "\n",
        "    # Step 3: Train the final model on the full training set\n",
        "    final_model = keras.Sequential([\n",
        "        keras.layers.Input(shape=(X_train_full.shape[1],)),\n",
        "        keras.layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=0.01, l2=0.01)),\n",
        "        keras.layers.Dense(32, activation='relu', kernel_regularizer=keras.regularizers.l1_l2(l1=0.01, l2=0.01)),\n",
        "        keras.layers.Dense(3, activation='softmax')  # 3 outputs for 3 classes\n",
        "    ])\n",
        "    final_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the final model\n",
        "    early_stopping_final = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        patience=patience,\n",
        "        restore_best_weights=True\n",
        "    )\n",
        "    final_model.fit(X_train_full, y_train_full, epochs=100, batch_size=32, validation_split=0.2, callbacks=[early_stopping_final])\n",
        "\n",
        "    # Step 4: Evaluate the final model on the test set\n",
        "    y_test_pred = final_model.predict(X_test) # if scaled therr will be X test scaled\n",
        "    y_test_pred_classes = np.argmax(y_test_pred, axis=1)\n",
        "\n",
        "    print(\"\\nFinal Model Evaluation on Test Set:\")\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(confusion_matrix(y_test, y_test_pred_classes))\n",
        "    print(classification_report(y_test, y_test_pred_classes))\n",
        "\n",
        "    with open('nn_model.pkl', 'wb') as f:\n",
        "      pickle.dump(final_model, f)\n",
        "\n",
        "    files.download('nn_model.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBtPcN56VB4H"
      },
      "source": [
        "# Approach 1 - Downsampling to 1hz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Wx0KBWJgAXZI"
      },
      "outputs": [],
      "source": [
        "#100HZ TO 1HZ\n",
        "PS1 = mean_conversion_1hz(pressureFile1)\n",
        "PS1.columns = [f'PS1_{i}' for i in range(PS1.shape[1])]\n",
        "\n",
        "PS2 = mean_conversion_1hz(pressureFile2)\n",
        "PS2.columns = [f'PS2_{i}' for i in range(PS2.shape[1])]\n",
        "\n",
        "PS3 = mean_conversion_1hz(pressureFile3)\n",
        "PS3.columns = [f'PS3_{i}' for i in range(PS3.shape[1])]\n",
        "\n",
        "PS4 = mean_conversion_1hz(pressureFile4)\n",
        "PS4.columns = [f'PS4_{i}' for i in range(PS4.shape[1])]\n",
        "\n",
        "PS5 = mean_conversion_1hz(pressureFile5)\n",
        "PS5.columns = [f'PS5_{i}' for i in range(PS5.shape[1])]\n",
        "\n",
        "PS6 = mean_conversion_1hz(pressureFile6)\n",
        "PS6.columns = [f'PS6_{i}' for i in range(PS6.shape[1])]\n",
        "\n",
        "P1 = mean_conversion_1hz(pump1)\n",
        "P1.columns = [f'P1_{i}' for i in range(P1.shape[1])]\n",
        "\n",
        "#10hz to 1hz\n",
        "\n",
        "FS1 = pd.DataFrame(mean_conversion_100hz(volumeFlow1))\n",
        "FS1.columns = [f'FS1_{i}' for i in range(FS1.shape[1])]\n",
        "\n",
        "FS2 = pd.DataFrame(mean_conversion_100hz(volumeFlow2))\n",
        "FS2.columns = [f'FS2_{i}' for i in range(FS2.shape[1])]\n",
        "\n",
        "#Leaving 1HZ as it is\n",
        "\n",
        "TS1 = pd.DataFrame(temperature1)\n",
        "TS1.columns = [f'TS1_{i}' for i in range(TS1.shape[1])]\n",
        "\n",
        "TS2 = pd.DataFrame(temperature2)\n",
        "TS2.columns = [f'TS2_{i}' for i in range(TS2.shape[1])]\n",
        "\n",
        "TS3 = pd.DataFrame(temperature3)\n",
        "TS3.columns = [f'TS3_{i}' for i in range(TS3.shape[1])]\n",
        "\n",
        "TS4 = pd.DataFrame(temperature4)\n",
        "TS4.columns = [f'TS4_{i}' for i in range(TS4.shape[1])]\n",
        "\n",
        "VS1 = pd.DataFrame(vibration1)\n",
        "VS1.columns = [f'VS1_{i}' for i in range(VS1.shape[1])]\n",
        "\n",
        "CE1 = pd.DataFrame(coolingE1)\n",
        "CE1.columns = [f'CE1_{i}' for i in range(CE1.shape[1])]\n",
        "\n",
        "CP1 = pd.DataFrame(coolingP1)\n",
        "CP1.columns = [f'CP1_{i}' for i in range(CP1.shape[1])]\n",
        "\n",
        "SE1 = pd.DataFrame(effFactor1)\n",
        "SE1.columns = [f'SE1_{i}' for i in range(SE1.shape[1])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhVRXSlNWjlt",
        "outputId": "79bffb0e-59a9-4100-985b-27f7fea2e67f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n",
            "(2205, 60)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "124"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "print(PS1.shape)\n",
        "print(PS2.shape)\n",
        "print(PS3.shape)\n",
        "print(PS4.shape)\n",
        "print(PS5.shape)\n",
        "print(PS6.shape)\n",
        "print(P1.shape)\n",
        "print(FS1.shape)\n",
        "print(FS2.shape)\n",
        "print(TS1.shape)\n",
        "print(TS2.shape)\n",
        "print(TS3.shape)\n",
        "print(TS4.shape)\n",
        "print(VS1.shape)\n",
        "print(CE1.shape)\n",
        "print(CP1.shape)\n",
        "print(SE1.shape)\n",
        "\n",
        "X = pd.concat([PS1, PS2, PS3, PS4, PS5, PS6, FS1, FS2, TS1, TS2, TS3, TS4, P1, VS1, CE1, CP1, SE1], axis=1)\n",
        "# del PS1, PS2, PS3, PS4, PS5, PS6, pressureFile3, pressureFile4, pressureFile5, pressureFile6, pressureFile1, pressureFile2, FS1, FS2, volumeFlow1, volumeFlow2\n",
        "# del temperature1, temperature2, temperature3, temperature4, pump1, vibration1, coolingE1, coolingP1, effFactor1\n",
        "# del profile, TS1, TS2, TS3, TS4, P1, VS1, CE1, CP1, SE1\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guAZ4hynooaS",
        "outputId": "b17720bd-b055-4667-881e-9f5fec19b34f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2205, 1020)\n"
          ]
        }
      ],
      "source": [
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X = pd.DataFrame(X)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "81uJitNU8oQT",
        "outputId": "b6229138-1948-4213-f20c-02d620acc6b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       310\n",
            "           1       0.97      0.93      0.95       131\n",
            "\n",
            "    accuracy                           0.97       441\n",
            "   macro avg       0.97      0.96      0.96       441\n",
            "weighted avg       0.97      0.97      0.97       441\n",
            "\n",
            "Fold 1 F1-score: 0.9704\n",
            "Fold 1 Accuracy: 0.9705\n",
            "Fold 1 Precision: 0.9705\n",
            "Confusion Matrix:\n",
            "[[306   4]\n",
            " [  9 122]]\n",
            "------------------------------\n",
            "Fold 2:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       277\n",
            "           1       0.97      0.92      0.95       164\n",
            "\n",
            "    accuracy                           0.96       441\n",
            "   macro avg       0.96      0.95      0.96       441\n",
            "weighted avg       0.96      0.96      0.96       441\n",
            "\n",
            "Fold 2 F1-score: 0.9612\n",
            "Fold 2 Accuracy: 0.9615\n",
            "Fold 2 Precision: 0.9619\n",
            "Confusion Matrix:\n",
            "[[273   4]\n",
            " [ 13 151]]\n",
            "------------------------------\n",
            "Fold 3:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.97      0.97       281\n",
            "           1       0.95      0.96      0.96       160\n",
            "\n",
            "    accuracy                           0.97       441\n",
            "   macro avg       0.96      0.97      0.97       441\n",
            "weighted avg       0.97      0.97      0.97       441\n",
            "\n",
            "Fold 3 F1-score: 0.9683\n",
            "Fold 3 Accuracy: 0.9683\n",
            "Fold 3 Precision: 0.9684\n",
            "Confusion Matrix:\n",
            "[[273   8]\n",
            " [  6 154]]\n",
            "------------------------------\n",
            "Fold 4:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       278\n",
            "           1       0.96      0.94      0.95       163\n",
            "\n",
            "    accuracy                           0.96       441\n",
            "   macro avg       0.96      0.96      0.96       441\n",
            "weighted avg       0.96      0.96      0.96       441\n",
            "\n",
            "Fold 4 F1-score: 0.9637\n",
            "Fold 4 Accuracy: 0.9637\n",
            "Fold 4 Precision: 0.9637\n",
            "Confusion Matrix:\n",
            "[[271   7]\n",
            " [  9 154]]\n",
            "------------------------------\n",
            "Fold 5:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       303\n",
            "           1       0.97      0.91      0.94       138\n",
            "\n",
            "    accuracy                           0.96       441\n",
            "   macro avg       0.97      0.95      0.96       441\n",
            "weighted avg       0.96      0.96      0.96       441\n",
            "\n",
            "Fold 5 F1-score: 0.9634\n",
            "Fold 5 Accuracy: 0.9637\n",
            "Fold 5 Precision: 0.9639\n",
            "Confusion Matrix:\n",
            "[[299   4]\n",
            " [ 12 126]]\n",
            "------------------------------\n",
            "Average F1-score across 5 folds: 0.9654\n",
            "Average Accuracy across 5 folds: 0.9655\n",
            "Average Precision across 5 folds: 0.9656\n",
            "Training final model on the entire dataset...\n",
            "Final Model Accuracy: 0.9660\n",
            "Final Model Precision: 0.9660\n",
            "Final Model Confusion Matrix:\n",
            "[[289   5]\n",
            " [ 10 137]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_23777b51-bc22-4723-ae6a-fad0c4fb53f7\", \"XGB_final_model.pkl\", 88044)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "xgb_(X, y_stableFlag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "cUD9nRvaElIx",
        "outputId": "634f3f12-ee49-465d-9eaa-35cbcd3e7888"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision scores for each fold: [0.8024691358024691, 0.865979381443299, 0.7959183673469388, 0.7551020408163265, 0.7551020408163265]\n",
            "Average precision: 0.7949141932450718\n",
            "Average accuracy: 0.8301706384230656\n",
            "Confusion matrix for training set:\n",
            " [[906  97]\n",
            " [165 375]]\n",
            "Test set accuracy: 0.8595166163141994\n",
            "Test set precision: 0.7374517374517374\n",
            "Test set confusion matrix:\n",
            " [[378  68]\n",
            " [ 25 191]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_cb3f7c05-8ccc-4841-87b6-42e8bfccb279\", \"svm_model.pkl\", 7862194)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "svm(X,y_stableFlag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "H-vtw2etPLic",
        "outputId": "d8bbe825-235c-4685-98f0-17c9e49b60b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       220\n",
            "           1       1.00      0.92      0.96       133\n",
            "\n",
            "    accuracy                           0.97       353\n",
            "   macro avg       0.98      0.96      0.97       353\n",
            "weighted avg       0.97      0.97      0.97       353\n",
            "\n",
            "Fold 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       234\n",
            "           1       1.00      0.97      0.99       119\n",
            "\n",
            "    accuracy                           0.99       353\n",
            "   macro avg       0.99      0.99      0.99       353\n",
            "weighted avg       0.99      0.99      0.99       353\n",
            "\n",
            "Fold 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       232\n",
            "           1       1.00      0.94      0.97       121\n",
            "\n",
            "    accuracy                           0.98       353\n",
            "   macro avg       0.99      0.97      0.98       353\n",
            "weighted avg       0.98      0.98      0.98       353\n",
            "\n",
            "Fold 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       237\n",
            "           1       1.00      0.92      0.96       116\n",
            "\n",
            "    accuracy                           0.97       353\n",
            "   macro avg       0.98      0.96      0.97       353\n",
            "weighted avg       0.98      0.97      0.97       353\n",
            "\n",
            "Fold 5 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       232\n",
            "           1       1.00      0.93      0.96       120\n",
            "\n",
            "    accuracy                           0.97       352\n",
            "   macro avg       0.98      0.96      0.97       352\n",
            "weighted avg       0.98      0.97      0.97       352\n",
            "\n",
            "Average Precision across 5 folds: 1.0\n",
            "Average Accuracy across 5 folds: 0.9784557687355138\n",
            "Final Test Set Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98       294\n",
            "           1       1.00      0.90      0.95       147\n",
            "\n",
            "    accuracy                           0.97       441\n",
            "   macro avg       0.98      0.95      0.96       441\n",
            "weighted avg       0.97      0.97      0.97       441\n",
            "\n",
            "Final Model Accuracy: 0.9682539682539683\n",
            "Final Model Precision: 1.0\n",
            "Confusion Matrix - Final Model (Test Set):\n",
            "[[294   0]\n",
            " [ 14 133]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_5545f086-2680-4300-9cda-557b52fff379\", \"rf_model.pkl\", 532590)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "randomforest(X,y_stableFlag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "AV_zAD22xF4y",
        "outputId": "d0d9ad57-d12e-422b-ed54-df62623cb648"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6370 - loss: 23.6368 - val_accuracy: 0.7309 - val_loss: 9.4082\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7701 - loss: 6.9525 - val_accuracy: 0.7252 - val_loss: 3.0452\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7020 - loss: 2.7588 - val_accuracy: 0.6969 - val_loss: 1.9541\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7479 - loss: 1.8091 - val_accuracy: 0.6941 - val_loss: 1.4612\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8019 - loss: 1.3178 - val_accuracy: 0.8414 - val_loss: 1.0814\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8223 - loss: 1.0258 - val_accuracy: 0.7592 - val_loss: 1.0193\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7482 - loss: 1.0398 - val_accuracy: 0.8272 - val_loss: 0.8494\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8684 - loss: 0.8045 - val_accuracy: 0.9008 - val_loss: 0.7773\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8642 - loss: 0.7524 - val_accuracy: 0.8725 - val_loss: 0.7784\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8118 - loss: 0.7469 - val_accuracy: 0.8867 - val_loss: 0.6924\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8893 - loss: 0.6746 - val_accuracy: 0.6601 - val_loss: 0.7881\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8263 - loss: 0.7216 - val_accuracy: 0.8584 - val_loss: 0.6622\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9025 - loss: 0.6246 - val_accuracy: 0.8839 - val_loss: 0.6353\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8928 - loss: 0.5892 - val_accuracy: 0.8612 - val_loss: 0.6444\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8635 - loss: 0.6371 - val_accuracy: 0.8385 - val_loss: 0.6514\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8579 - loss: 0.6046 - val_accuracy: 0.8300 - val_loss: 0.6394\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8658 - loss: 0.6066 - val_accuracy: 0.9122 - val_loss: 0.5765\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8861 - loss: 0.5808 - val_accuracy: 0.9122 - val_loss: 0.5829\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9093 - loss: 0.5436 - val_accuracy: 0.8867 - val_loss: 0.5564\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9076 - loss: 0.5318 - val_accuracy: 0.8697 - val_loss: 0.5744\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8926 - loss: 0.5608 - val_accuracy: 0.8584 - val_loss: 0.5795\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8832 - loss: 0.5550 - val_accuracy: 0.8669 - val_loss: 0.5640\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8898 - loss: 0.5434 - val_accuracy: 0.8952 - val_loss: 0.5439\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.5222 - val_accuracy: 0.8867 - val_loss: 0.5378\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9023 - loss: 0.5181 - val_accuracy: 0.8612 - val_loss: 0.5937\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8706 - loss: 0.5557 - val_accuracy: 0.9122 - val_loss: 0.5148\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9012 - loss: 0.5199 - val_accuracy: 0.8697 - val_loss: 0.5419\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9132 - loss: 0.4990 - val_accuracy: 0.7875 - val_loss: 0.6469\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8766 - loss: 0.5469 - val_accuracy: 0.8952 - val_loss: 0.5087\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9103 - loss: 0.5010 - val_accuracy: 0.8924 - val_loss: 0.5054\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8847 - loss: 0.5139 - val_accuracy: 0.8272 - val_loss: 0.5739\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8508 - loss: 0.5876 - val_accuracy: 0.9065 - val_loss: 0.5555\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9044 - loss: 0.5105 - val_accuracy: 0.8952 - val_loss: 0.5194\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9001 - loss: 0.5055 - val_accuracy: 0.9235 - val_loss: 0.5310\n",
            "Epoch 35/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9201 - loss: 0.4819 - val_accuracy: 0.8952 - val_loss: 0.4913\n",
            "Epoch 36/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.4693 - val_accuracy: 0.9178 - val_loss: 0.5289\n",
            "Epoch 37/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9182 - loss: 0.4703 - val_accuracy: 0.8895 - val_loss: 0.5021\n",
            "Epoch 38/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9059 - loss: 0.4795 - val_accuracy: 0.9150 - val_loss: 0.5076\n",
            "Epoch 39/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8976 - loss: 0.4928 - val_accuracy: 0.9122 - val_loss: 0.4896\n",
            "Epoch 40/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8651 - loss: 0.5441 - val_accuracy: 0.9093 - val_loss: 0.4833\n",
            "Epoch 41/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.4887 - val_accuracy: 0.8640 - val_loss: 0.5252\n",
            "Epoch 42/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8952 - loss: 0.4972 - val_accuracy: 0.9235 - val_loss: 0.5113\n",
            "Epoch 43/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8889 - loss: 0.5243 - val_accuracy: 0.9207 - val_loss: 0.4726\n",
            "Epoch 44/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9172 - loss: 0.4508 - val_accuracy: 0.9122 - val_loss: 0.4713\n",
            "Epoch 45/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9255 - loss: 0.4504 - val_accuracy: 0.9065 - val_loss: 0.4738\n",
            "Epoch 46/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9041 - loss: 0.4693 - val_accuracy: 0.9235 - val_loss: 0.5026\n",
            "Epoch 47/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9103 - loss: 0.4759 - val_accuracy: 0.8612 - val_loss: 0.5375\n",
            "Epoch 48/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8996 - loss: 0.4897 - val_accuracy: 0.8555 - val_loss: 0.5429\n",
            "Epoch 49/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9052 - loss: 0.4933 - val_accuracy: 0.8924 - val_loss: 0.4928\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Fold 1:\n",
            "Validation Confusion Matrix:\n",
            "[[195  25]\n",
            " [  6 127]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.89      0.93       220\n",
            "           1       0.84      0.95      0.89       133\n",
            "\n",
            "    accuracy                           0.91       353\n",
            "   macro avg       0.90      0.92      0.91       353\n",
            "weighted avg       0.92      0.91      0.91       353\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6646 - loss: 23.5130 - val_accuracy: 0.8045 - val_loss: 9.0047\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7212 - loss: 6.6806 - val_accuracy: 0.8215 - val_loss: 2.8358\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7787 - loss: 2.5062 - val_accuracy: 0.6629 - val_loss: 1.7895\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7652 - loss: 1.6553 - val_accuracy: 0.7960 - val_loss: 1.3116\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7756 - loss: 1.2436 - val_accuracy: 0.8527 - val_loss: 0.9435\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8329 - loss: 0.9344 - val_accuracy: 0.8357 - val_loss: 0.8508\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7979 - loss: 0.8608 - val_accuracy: 0.6629 - val_loss: 0.9046\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8178 - loss: 0.8228 - val_accuracy: 0.9150 - val_loss: 0.6938\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8611 - loss: 0.7224 - val_accuracy: 0.7620 - val_loss: 0.8510\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8375 - loss: 0.7653 - val_accuracy: 0.8895 - val_loss: 0.6292\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8692 - loss: 0.6651 - val_accuracy: 0.9377 - val_loss: 0.6096\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8461 - loss: 0.7058 - val_accuracy: 0.9207 - val_loss: 0.6082\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8804 - loss: 0.6309 - val_accuracy: 0.8980 - val_loss: 0.5728\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8945 - loss: 0.6027 - val_accuracy: 0.9065 - val_loss: 0.5662\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8800 - loss: 0.5878 - val_accuracy: 0.8839 - val_loss: 0.5691\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8750 - loss: 0.6025 - val_accuracy: 0.8924 - val_loss: 0.5290\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8786 - loss: 0.5837 - val_accuracy: 0.9065 - val_loss: 0.5026\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8861 - loss: 0.5635 - val_accuracy: 0.8952 - val_loss: 0.5458\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8452 - loss: 0.6299 - val_accuracy: 0.9263 - val_loss: 0.4941\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8857 - loss: 0.5645 - val_accuracy: 0.9122 - val_loss: 0.4983\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9068 - loss: 0.5373 - val_accuracy: 0.8867 - val_loss: 0.5187\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9016 - loss: 0.5334 - val_accuracy: 0.9207 - val_loss: 0.4693\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9047 - loss: 0.5156 - val_accuracy: 0.6771 - val_loss: 0.6651\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7998 - loss: 0.6163 - val_accuracy: 0.8697 - val_loss: 0.4901\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8696 - loss: 0.5243 - val_accuracy: 0.9207 - val_loss: 0.4570\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8808 - loss: 0.5397 - val_accuracy: 0.9093 - val_loss: 0.4692\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9024 - loss: 0.4902 - val_accuracy: 0.9207 - val_loss: 0.4669\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9085 - loss: 0.5101 - val_accuracy: 0.8952 - val_loss: 0.4713\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8768 - loss: 0.5359 - val_accuracy: 0.9178 - val_loss: 0.4850\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9214 - loss: 0.4716 - val_accuracy: 0.9292 - val_loss: 0.4217\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8986 - loss: 0.4896 - val_accuracy: 0.9292 - val_loss: 0.4165\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9096 - loss: 0.4715 - val_accuracy: 0.8329 - val_loss: 0.5300\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8797 - loss: 0.5133 - val_accuracy: 0.9178 - val_loss: 0.4365\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8521 - loss: 0.5221 - val_accuracy: 0.9320 - val_loss: 0.4201\n",
            "Epoch 35/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9001 - loss: 0.4581 - val_accuracy: 0.8244 - val_loss: 0.5391\n",
            "Epoch 36/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8299 - loss: 0.5285 - val_accuracy: 0.8924 - val_loss: 0.4406\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Fold 2:\n",
            "Validation Confusion Matrix:\n",
            "[[214  20]\n",
            " [  5 114]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.91      0.94       234\n",
            "           1       0.85      0.96      0.90       119\n",
            "\n",
            "    accuracy                           0.93       353\n",
            "   macro avg       0.91      0.94      0.92       353\n",
            "weighted avg       0.93      0.93      0.93       353\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 15ms/step - accuracy: 0.6594 - loss: 23.5866 - val_accuracy: 0.7649 - val_loss: 9.2486\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7079 - loss: 6.7511 - val_accuracy: 0.6969 - val_loss: 2.7536\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7440 - loss: 2.3690 - val_accuracy: 0.6856 - val_loss: 1.7112\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7287 - loss: 1.5811 - val_accuracy: 0.8074 - val_loss: 1.2908\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8076 - loss: 1.2034 - val_accuracy: 0.6572 - val_loss: 1.0707\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7683 - loss: 0.9930 - val_accuracy: 0.7450 - val_loss: 0.8727\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8338 - loss: 0.8314 - val_accuracy: 0.8244 - val_loss: 0.8156\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8669 - loss: 0.7513 - val_accuracy: 0.8782 - val_loss: 0.7440\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8453 - loss: 0.7309 - val_accuracy: 0.8839 - val_loss: 0.6932\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8975 - loss: 0.6496 - val_accuracy: 0.8244 - val_loss: 0.6876\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8543 - loss: 0.6642 - val_accuracy: 0.8697 - val_loss: 0.6689\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9016 - loss: 0.6193 - val_accuracy: 0.8867 - val_loss: 0.6145\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9005 - loss: 0.5993 - val_accuracy: 0.8952 - val_loss: 0.6036\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9051 - loss: 0.5848 - val_accuracy: 0.8159 - val_loss: 0.6959\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8650 - loss: 0.6040 - val_accuracy: 0.8215 - val_loss: 0.7103\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8690 - loss: 0.6159 - val_accuracy: 0.8442 - val_loss: 0.6321\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8930 - loss: 0.5791 - val_accuracy: 0.8895 - val_loss: 0.5608\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8932 - loss: 0.5389 - val_accuracy: 0.9008 - val_loss: 0.5765\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9022 - loss: 0.5391 - val_accuracy: 0.9037 - val_loss: 0.5811\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8933 - loss: 0.5332 - val_accuracy: 0.8810 - val_loss: 0.5475\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8753 - loss: 0.5356 - val_accuracy: 0.9093 - val_loss: 0.5326\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9008 - loss: 0.5321 - val_accuracy: 0.8442 - val_loss: 0.6195\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8863 - loss: 0.5385 - val_accuracy: 0.8527 - val_loss: 0.5896\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9087 - loss: 0.5125 - val_accuracy: 0.9008 - val_loss: 0.5455\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8690 - loss: 0.5522 - val_accuracy: 0.9037 - val_loss: 0.5178\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.4842 - val_accuracy: 0.9093 - val_loss: 0.5151\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9212 - loss: 0.4775 - val_accuracy: 0.8300 - val_loss: 0.5855\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8954 - loss: 0.5109 - val_accuracy: 0.8612 - val_loss: 0.5488\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.4918 - val_accuracy: 0.8329 - val_loss: 0.6055\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8882 - loss: 0.5299 - val_accuracy: 0.8924 - val_loss: 0.4996\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9058 - loss: 0.4889 - val_accuracy: 0.8074 - val_loss: 0.6981\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 0.5648 - val_accuracy: 0.9065 - val_loss: 0.4912\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8815 - loss: 0.5141 - val_accuracy: 0.8895 - val_loss: 0.5083\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9065 - loss: 0.4768 - val_accuracy: 0.8272 - val_loss: 0.6206\n",
            "Epoch 35/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8969 - loss: 0.5034 - val_accuracy: 0.9008 - val_loss: 0.4884\n",
            "Epoch 36/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8760 - loss: 0.5061 - val_accuracy: 0.8300 - val_loss: 0.5880\n",
            "Epoch 37/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8240 - loss: 0.6282 - val_accuracy: 0.8584 - val_loss: 0.5279\n",
            "Epoch 38/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8949 - loss: 0.4782 - val_accuracy: 0.8867 - val_loss: 0.4870\n",
            "Epoch 39/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9006 - loss: 0.4707 - val_accuracy: 0.8782 - val_loss: 0.5073\n",
            "Epoch 40/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9161 - loss: 0.4564 - val_accuracy: 0.9093 - val_loss: 0.4793\n",
            "Epoch 41/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9210 - loss: 0.4571 - val_accuracy: 0.8385 - val_loss: 0.5781\n",
            "Epoch 42/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8951 - loss: 0.4882 - val_accuracy: 0.9150 - val_loss: 0.4981\n",
            "Epoch 43/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8638 - loss: 0.5266 - val_accuracy: 0.8782 - val_loss: 0.4994\n",
            "Epoch 44/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8965 - loss: 0.4981 - val_accuracy: 0.7705 - val_loss: 0.6061\n",
            "Epoch 45/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8215 - loss: 0.5891 - val_accuracy: 0.8810 - val_loss: 0.5031\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
            "Fold 3:\n",
            "Validation Confusion Matrix:\n",
            "[[209  23]\n",
            " [  9 112]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.90      0.93       232\n",
            "           1       0.83      0.93      0.88       121\n",
            "\n",
            "    accuracy                           0.91       353\n",
            "   macro avg       0.89      0.91      0.90       353\n",
            "weighted avg       0.91      0.91      0.91       353\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 14ms/step - accuracy: 0.6259 - loss: 23.4184 - val_accuracy: 0.6714 - val_loss: 8.8424\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6422 - loss: 6.4525 - val_accuracy: 0.6714 - val_loss: 2.6441\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6515 - loss: 2.3449 - val_accuracy: 0.6714 - val_loss: 1.7067\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6683 - loss: 1.6157 - val_accuracy: 0.7167 - val_loss: 1.2804\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7277 - loss: 1.2285 - val_accuracy: 0.7535 - val_loss: 1.0287\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7498 - loss: 0.9926 - val_accuracy: 0.8300 - val_loss: 0.8854\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8120 - loss: 0.8717 - val_accuracy: 0.6714 - val_loss: 0.8810\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7776 - loss: 0.8186 - val_accuracy: 0.9008 - val_loss: 0.7276\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8907 - loss: 0.7157 - val_accuracy: 0.9037 - val_loss: 0.6787\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8157 - loss: 0.7322 - val_accuracy: 0.6742 - val_loss: 0.7655\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7708 - loss: 0.7238 - val_accuracy: 0.8952 - val_loss: 0.6413\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8715 - loss: 0.6342 - val_accuracy: 0.8357 - val_loss: 0.6652\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8555 - loss: 0.6360 - val_accuracy: 0.8669 - val_loss: 0.6120\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.5990 - val_accuracy: 0.8527 - val_loss: 0.6251\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8643 - loss: 0.5915 - val_accuracy: 0.9037 - val_loss: 0.5289\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8728 - loss: 0.5758 - val_accuracy: 0.9065 - val_loss: 0.5150\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8856 - loss: 0.5505 - val_accuracy: 0.8697 - val_loss: 0.5512\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8624 - loss: 0.5628 - val_accuracy: 0.9348 - val_loss: 0.5004\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9070 - loss: 0.5157 - val_accuracy: 0.8329 - val_loss: 0.5579\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8248 - loss: 0.6064 - val_accuracy: 0.9065 - val_loss: 0.4904\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8738 - loss: 0.5382 - val_accuracy: 0.8754 - val_loss: 0.5195\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8934 - loss: 0.5021 - val_accuracy: 0.8640 - val_loss: 0.5534\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.5528 - val_accuracy: 0.9093 - val_loss: 0.4725\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9002 - loss: 0.5108 - val_accuracy: 0.8952 - val_loss: 0.4912\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8827 - loss: 0.5021 - val_accuracy: 0.8754 - val_loss: 0.5087\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8876 - loss: 0.5105 - val_accuracy: 0.8640 - val_loss: 0.5385\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8347 - loss: 0.5697 - val_accuracy: 0.9122 - val_loss: 0.4568\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9054 - loss: 0.4726 - val_accuracy: 0.9150 - val_loss: 0.4459\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8816 - loss: 0.5111 - val_accuracy: 0.9348 - val_loss: 0.4594\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9175 - loss: 0.4652 - val_accuracy: 0.9008 - val_loss: 0.4754\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8956 - loss: 0.4901 - val_accuracy: 0.9320 - val_loss: 0.4298\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9141 - loss: 0.4691 - val_accuracy: 0.9178 - val_loss: 0.4750\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9064 - loss: 0.4729 - val_accuracy: 0.9150 - val_loss: 0.4445\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9141 - loss: 0.4546 - val_accuracy: 0.9348 - val_loss: 0.4362\n",
            "Epoch 35/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8966 - loss: 0.4682 - val_accuracy: 0.9150 - val_loss: 0.4451\n",
            "Epoch 36/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8981 - loss: 0.4812 - val_accuracy: 0.8640 - val_loss: 0.5030\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Fold 4:\n",
            "Validation Confusion Matrix:\n",
            "[[219  18]\n",
            " [  6 110]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.92      0.95       237\n",
            "           1       0.86      0.95      0.90       116\n",
            "\n",
            "    accuracy                           0.93       353\n",
            "   macro avg       0.92      0.94      0.92       353\n",
            "weighted avg       0.94      0.93      0.93       353\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6740 - loss: 23.1786 - val_accuracy: 0.7131 - val_loss: 8.6503\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7121 - loss: 6.2782 - val_accuracy: 0.7330 - val_loss: 2.6148\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6793 - loss: 2.3585 - val_accuracy: 0.6591 - val_loss: 1.7060\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6900 - loss: 1.5914 - val_accuracy: 0.6591 - val_loss: 1.3771\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7315 - loss: 1.2406 - val_accuracy: 0.8466 - val_loss: 0.9882\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7847 - loss: 0.9578 - val_accuracy: 0.6676 - val_loss: 0.8629\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7918 - loss: 0.8504 - val_accuracy: 0.7812 - val_loss: 0.8213\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8013 - loss: 0.7782 - val_accuracy: 0.8778 - val_loss: 0.7131\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.8385 - loss: 0.7298 - val_accuracy: 0.7386 - val_loss: 0.7121\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8139 - loss: 0.6997 - val_accuracy: 0.8835 - val_loss: 0.6529\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8203 - loss: 0.6974 - val_accuracy: 0.6591 - val_loss: 0.8284\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7442 - loss: 0.7671 - val_accuracy: 0.6761 - val_loss: 0.7131\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8258 - loss: 0.6710 - val_accuracy: 0.8750 - val_loss: 0.6238\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8869 - loss: 0.6029 - val_accuracy: 0.9091 - val_loss: 0.5868\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9103 - loss: 0.5851 - val_accuracy: 0.9091 - val_loss: 0.5691\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8934 - loss: 0.5750 - val_accuracy: 0.9091 - val_loss: 0.5564\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9008 - loss: 0.5808 - val_accuracy: 0.8466 - val_loss: 0.5888\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8716 - loss: 0.5728 - val_accuracy: 0.8722 - val_loss: 0.5576\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8358 - loss: 0.6119 - val_accuracy: 0.9034 - val_loss: 0.5433\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8954 - loss: 0.5447 - val_accuracy: 0.8920 - val_loss: 0.5233\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.5298 - val_accuracy: 0.8920 - val_loss: 0.5071\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8739 - loss: 0.5533 - val_accuracy: 0.9261 - val_loss: 0.5094\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9018 - loss: 0.5177 - val_accuracy: 0.8892 - val_loss: 0.4950\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9019 - loss: 0.5063 - val_accuracy: 0.9062 - val_loss: 0.4918\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9073 - loss: 0.4971 - val_accuracy: 0.8864 - val_loss: 0.5173\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9141 - loss: 0.4936 - val_accuracy: 0.8835 - val_loss: 0.5042\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9030 - loss: 0.4900 - val_accuracy: 0.8352 - val_loss: 0.5521\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8557 - loss: 0.5417 - val_accuracy: 0.8920 - val_loss: 0.4797\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9020 - loss: 0.4910 - val_accuracy: 0.9261 - val_loss: 0.4626\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9056 - loss: 0.4865 - val_accuracy: 0.9006 - val_loss: 0.4850\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8783 - loss: 0.5180 - val_accuracy: 0.8807 - val_loss: 0.5412\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8978 - loss: 0.4946 - val_accuracy: 0.9233 - val_loss: 0.4733\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8785 - loss: 0.5195 - val_accuracy: 0.8636 - val_loss: 0.5454\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8707 - loss: 0.5444 - val_accuracy: 0.8239 - val_loss: 0.5525\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
            "Fold 5:\n",
            "Validation Confusion Matrix:\n",
            "[[216  16]\n",
            " [ 10 110]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.93      0.94       232\n",
            "           1       0.87      0.92      0.89       120\n",
            "\n",
            "    accuracy                           0.93       352\n",
            "   macro avg       0.91      0.92      0.92       352\n",
            "weighted avg       0.93      0.93      0.93       352\n",
            "\n",
            "Average Accuracy across all folds: 0.9218\n",
            "Average Precision across all folds: 0.9264\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.7315 - loss: 23.2306 - val_accuracy: 0.7592 - val_loss: 8.8259\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7615 - loss: 6.4975 - val_accuracy: 0.7677 - val_loss: 2.8130\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7410 - loss: 2.5183 - val_accuracy: 0.6799 - val_loss: 1.7833\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8179 - loss: 1.6500 - val_accuracy: 0.6941 - val_loss: 1.3491\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7429 - loss: 1.2761 - val_accuracy: 0.9122 - val_loss: 0.9833\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8699 - loss: 0.9509 - val_accuracy: 0.8187 - val_loss: 0.8883\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8443 - loss: 0.8451 - val_accuracy: 0.7819 - val_loss: 0.8160\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8574 - loss: 0.7817 - val_accuracy: 0.8640 - val_loss: 0.7121\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8880 - loss: 0.7237 - val_accuracy: 0.9292 - val_loss: 0.6719\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.8882 - loss: 0.6862 - val_accuracy: 0.8499 - val_loss: 0.6735\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8524 - loss: 0.6967 - val_accuracy: 0.8669 - val_loss: 0.6465\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8601 - loss: 0.6580 - val_accuracy: 0.9348 - val_loss: 0.6185\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8869 - loss: 0.6351 - val_accuracy: 0.9008 - val_loss: 0.6128\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8832 - loss: 0.6238 - val_accuracy: 0.8895 - val_loss: 0.5943\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8305 - loss: 0.6630 - val_accuracy: 0.9008 - val_loss: 0.5885\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9176 - loss: 0.5788 - val_accuracy: 0.9122 - val_loss: 0.5642\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.8731 - loss: 0.6135 - val_accuracy: 0.8924 - val_loss: 0.5658\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8743 - loss: 0.6077 - val_accuracy: 0.9065 - val_loss: 0.5805\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8540 - loss: 0.6147 - val_accuracy: 0.9377 - val_loss: 0.5335\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.5570 - val_accuracy: 0.8640 - val_loss: 0.5735\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9095 - loss: 0.5388 - val_accuracy: 0.9122 - val_loss: 0.5280\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8912 - loss: 0.5419 - val_accuracy: 0.9320 - val_loss: 0.5079\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8894 - loss: 0.5287 - val_accuracy: 0.8499 - val_loss: 0.5677\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8488 - loss: 0.5631 - val_accuracy: 0.8952 - val_loss: 0.4974\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8683 - loss: 0.5511 - val_accuracy: 0.9122 - val_loss: 0.5003\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9104 - loss: 0.5033 - val_accuracy: 0.9377 - val_loss: 0.4740\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8680 - loss: 0.5342 - val_accuracy: 0.7847 - val_loss: 0.6012\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8493 - loss: 0.5756 - val_accuracy: 0.9093 - val_loss: 0.5026\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8979 - loss: 0.5092 - val_accuracy: 0.9433 - val_loss: 0.4712\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9081 - loss: 0.4969 - val_accuracy: 0.9320 - val_loss: 0.4608\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8939 - loss: 0.5106 - val_accuracy: 0.9263 - val_loss: 0.4533\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8864 - loss: 0.5072 - val_accuracy: 0.9405 - val_loss: 0.4571\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8975 - loss: 0.4856 - val_accuracy: 0.8952 - val_loss: 0.4638\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8681 - loss: 0.5261 - val_accuracy: 0.9207 - val_loss: 0.4650\n",
            "Epoch 35/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8897 - loss: 0.4961 - val_accuracy: 0.9093 - val_loss: 0.4738\n",
            "Epoch 36/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8777 - loss: 0.5151 - val_accuracy: 0.9462 - val_loss: 0.4447\n",
            "Epoch 37/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9061 - loss: 0.4661 - val_accuracy: 0.9433 - val_loss: 0.4671\n",
            "Epoch 38/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9090 - loss: 0.4831 - val_accuracy: 0.9433 - val_loss: 0.4555\n",
            "Epoch 39/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8981 - loss: 0.4935 - val_accuracy: 0.9377 - val_loss: 0.4382\n",
            "Epoch 40/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9032 - loss: 0.4754 - val_accuracy: 0.9433 - val_loss: 0.4390\n",
            "Epoch 41/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8725 - loss: 0.5284 - val_accuracy: 0.9433 - val_loss: 0.4384\n",
            "Epoch 42/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9111 - loss: 0.4655 - val_accuracy: 0.9292 - val_loss: 0.4801\n",
            "Epoch 43/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8940 - loss: 0.4945 - val_accuracy: 0.8810 - val_loss: 0.4715\n",
            "Epoch 44/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8740 - loss: 0.5075 - val_accuracy: 0.8810 - val_loss: 0.4811\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\n",
            "Final Model Evaluation on Test Set:\n",
            "Confusion Matrix:\n",
            "[[282  12]\n",
            " [ 16 131]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95       294\n",
            "           1       0.92      0.89      0.90       147\n",
            "\n",
            "    accuracy                           0.94       441\n",
            "   macro avg       0.93      0.93      0.93       441\n",
            "weighted avg       0.94      0.94      0.94       441\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e3c925c0-4c17-4557-98e2-9c10e15b060a\", \"nn_model.pkl\", 831510)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "neuralnetwork(X,y_stableFlag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmVKxoOjWQ0h"
      },
      "source": [
        "# Approach 2 - Upsampling and Downsampling to 10hz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "V2s6S1vGwiB4"
      },
      "outputs": [],
      "source": [
        "#100HZ TO 10HZ\n",
        "PS1 = mean_conversion_100hz(pressureFile1)\n",
        "PS1.columns = [f'PS1_{i}' for i in range(PS1.shape[1])]\n",
        "\n",
        "PS2 = mean_conversion_100hz(pressureFile2)\n",
        "PS2.columns = [f'PS2_{i}' for i in range(PS2.shape[1])]\n",
        "\n",
        "PS3 = mean_conversion_100hz(pressureFile3)\n",
        "PS3.columns = [f'PS3_{i}' for i in range(PS3.shape[1])]\n",
        "\n",
        "PS4 = mean_conversion_100hz(pressureFile4)\n",
        "PS4.columns = [f'PS4_{i}' for i in range(PS4.shape[1])]\n",
        "\n",
        "PS5 = mean_conversion_100hz(pressureFile5)\n",
        "PS5.columns = [f'PS5_{i}' for i in range(PS5.shape[1])]\n",
        "\n",
        "PS6 = mean_conversion_100hz(pressureFile6)\n",
        "PS6.columns = [f'PS6_{i}' for i in range(PS6.shape[1])]\n",
        "\n",
        "P1 = mean_conversion_100hz(pump1)\n",
        "P1.columns = [f'P1_{i}' for i in range(P1.shape[1])]\n",
        "\n",
        "#Leaving 10HZ as it is\n",
        "\n",
        "FS1 = pd.DataFrame(volumeFlow1)\n",
        "FS1.columns = [f'FS1_{i}' for i in range(FS1.shape[1])]\n",
        "\n",
        "FS2 = pd.DataFrame(volumeFlow2)\n",
        "FS2.columns = [f'FS2_{i}' for i in range(FS2.shape[1])]\n",
        "\n",
        "#1HZ to 10HZ\n",
        "\n",
        "\n",
        "TS1 = repeat_values(temperature1)\n",
        "TS1.columns = [f'TS1_{i}' for i in range(TS1.shape[1])]\n",
        "\n",
        "TS2 = repeat_values(temperature1)\n",
        "TS2.columns = [f'TS1_{i}' for i in range(TS2.shape[1])]\n",
        "\n",
        "TS3 = repeat_values(temperature1)\n",
        "TS3.columns = [f'TS1_{i}' for i in range(TS3.shape[1])]\n",
        "\n",
        "TS4 = repeat_values(temperature1)\n",
        "TS4.columns = [f'TS1_{i}' for i in range(TS4.shape[1])]\n",
        "\n",
        "VS1 = repeat_values(vibration1)\n",
        "VS1.columns = [f'VS1_{i}' for i in range(VS1.shape[1])]\n",
        "\n",
        "CE1 = repeat_values(coolingE1)\n",
        "CE1.columns = [f'CE1_{i}' for i in range(CE1.shape[1])]\n",
        "\n",
        "CP1 = repeat_values(coolingP1)\n",
        "CP1.columns = [f'CP1_{i}' for i in range(CP1.shape[1])]\n",
        "\n",
        "SE1 = repeat_values(effFactor1)\n",
        "SE1.columns = [f'SE1_{i}' for i in range(SE1.shape[1])]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_48P8xtYfDZ",
        "outputId": "9baebe8d-6f9a-442d-842c-78cb65b7534f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n",
            "(2205, 600)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "29329"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "print(PS1.shape)\n",
        "print(PS2.shape)\n",
        "print(PS3.shape)\n",
        "print(PS4.shape)\n",
        "print(PS5.shape)\n",
        "print(PS6.shape)\n",
        "print(P1.shape)\n",
        "print(FS1.shape)\n",
        "print(FS2.shape)\n",
        "print(TS1.shape)\n",
        "print(TS2.shape)\n",
        "print(TS3.shape)\n",
        "print(TS4.shape)\n",
        "print(VS1.shape)\n",
        "print(CE1.shape)\n",
        "print(CP1.shape)\n",
        "print(SE1.shape)\n",
        "\n",
        "X = pd.concat([PS1, PS2, PS3, PS4, PS5, PS6, FS1, FS2, TS1, TS2, TS3, TS4, P1, VS1, CE1, CP1, SE1], axis=1)\n",
        "# del PS1, PS2, PS3, PS4, PS5, PS6, pressureFile3, pressureFile4, pressureFile5, pressureFile6, pressureFile1, pressureFile2, FS1, FS2, volumeFlow1, volumeFlow2\n",
        "# del temperature1, temperature2, temperature3, temperature4, pump1, vibration1, coolingE1, coolingP1, effFactor1\n",
        "# del profile, TS1, TS2, TS3, TS4, P1, VS1, CE1, CP1, SE1\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAZm8m7sYjCS",
        "outputId": "cb6b49ba-c4ad-4200-d7a9-5d4310549e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2205, 10200)\n"
          ]
        }
      ],
      "source": [
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X = pd.DataFrame(X)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7fX4exu3YyS6",
        "outputId": "7833b7fd-46d5-4f20-d6a4-b5b134865595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.99      0.98       310\n",
            "           1       0.97      0.94      0.95       131\n",
            "\n",
            "    accuracy                           0.97       441\n",
            "   macro avg       0.97      0.96      0.97       441\n",
            "weighted avg       0.97      0.97      0.97       441\n",
            "\n",
            "Fold 1 F1-score: 0.9727\n",
            "Fold 1 Accuracy: 0.9728\n",
            "Fold 1 Precision: 0.9727\n",
            "Confusion Matrix:\n",
            "[[306   4]\n",
            " [  8 123]]\n",
            "------------------------------\n",
            "Fold 2:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96       277\n",
            "           1       0.96      0.91      0.93       164\n",
            "\n",
            "    accuracy                           0.95       441\n",
            "   macro avg       0.95      0.94      0.95       441\n",
            "weighted avg       0.95      0.95      0.95       441\n",
            "\n",
            "Fold 2 F1-score: 0.9498\n",
            "Fold 2 Accuracy: 0.9501\n",
            "Fold 2 Precision: 0.9503\n",
            "Confusion Matrix:\n",
            "[[270   7]\n",
            " [ 15 149]]\n",
            "------------------------------\n",
            "Fold 3:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       281\n",
            "           1       0.96      0.96      0.96       160\n",
            "\n",
            "    accuracy                           0.97       441\n",
            "   macro avg       0.97      0.97      0.97       441\n",
            "weighted avg       0.97      0.97      0.97       441\n",
            "\n",
            "Fold 3 F1-score: 0.9705\n",
            "Fold 3 Accuracy: 0.9705\n",
            "Fold 3 Precision: 0.9706\n",
            "Confusion Matrix:\n",
            "[[274   7]\n",
            " [  6 154]]\n",
            "------------------------------\n",
            "Fold 4:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.97      0.97       278\n",
            "           1       0.96      0.95      0.95       163\n",
            "\n",
            "    accuracy                           0.97       441\n",
            "   macro avg       0.96      0.96      0.96       441\n",
            "weighted avg       0.97      0.97      0.97       441\n",
            "\n",
            "Fold 4 F1-score: 0.9660\n",
            "Fold 4 Accuracy: 0.9660\n",
            "Fold 4 Precision: 0.9660\n",
            "Confusion Matrix:\n",
            "[[271   7]\n",
            " [  8 155]]\n",
            "------------------------------\n",
            "Fold 5:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.97       303\n",
            "           1       0.97      0.91      0.94       138\n",
            "\n",
            "    accuracy                           0.96       441\n",
            "   macro avg       0.96      0.95      0.95       441\n",
            "weighted avg       0.96      0.96      0.96       441\n",
            "\n",
            "Fold 5 F1-score: 0.9611\n",
            "Fold 5 Accuracy: 0.9615\n",
            "Fold 5 Precision: 0.9617\n",
            "Confusion Matrix:\n",
            "[[299   4]\n",
            " [ 13 125]]\n",
            "------------------------------\n",
            "Average F1-score across 5 folds: 0.9640\n",
            "Average Accuracy across 5 folds: 0.9642\n",
            "Average Precision across 5 folds: 0.9642\n",
            "Training final model on the entire dataset...\n",
            "Final Model Accuracy: 0.9615\n",
            "Final Model Precision: 0.9617\n",
            "Final Model Confusion Matrix:\n",
            "[[290   4]\n",
            " [ 13 134]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c7a015ad-c6f5-41c7-a670-949a3f3a4ef9\", \"XGB_final_model.pkl\", 85287)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "xgb_(X, y_stableFlag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "xrca_IK8Zp5K",
        "outputId": "62ebee22-6750-4480-99f7-744418bd2bfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision scores for each fold: [0.9130434782608695, 0.8979591836734694, 0.8363636363636363, 0.7543859649122807, 0.8125]\n",
            "Average precision: 0.842850452642051\n",
            "Average accuracy: 0.7621233135796242\n",
            "Confusion matrix for training set:\n",
            " [[962  41]\n",
            " [326 214]]\n",
            "Test set accuracy: 0.9018126888217523\n",
            "Test set precision: 0.8296943231441049\n",
            "Test set confusion matrix:\n",
            " [[407  39]\n",
            " [ 26 190]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_138a37fe-c1a7-443f-b0cd-82c056d15d18\", \"svm_model.pkl\", 78682894)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "svm(X,y_stableFlag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pHyE8aqLZqPG",
        "outputId": "d68ccff1-95af-4cd8-fc22-91dbf7f6c0f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       220\n",
            "           1       1.00      0.93      0.96       133\n",
            "\n",
            "    accuracy                           0.97       353\n",
            "   macro avg       0.98      0.97      0.97       353\n",
            "weighted avg       0.98      0.97      0.97       353\n",
            "\n",
            "Fold 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       234\n",
            "           1       0.98      0.97      0.98       119\n",
            "\n",
            "    accuracy                           0.99       353\n",
            "   macro avg       0.99      0.98      0.98       353\n",
            "weighted avg       0.99      0.99      0.99       353\n",
            "\n",
            "Fold 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       232\n",
            "           1       1.00      0.94      0.97       121\n",
            "\n",
            "    accuracy                           0.98       353\n",
            "   macro avg       0.99      0.97      0.98       353\n",
            "weighted avg       0.98      0.98      0.98       353\n",
            "\n",
            "Fold 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99       237\n",
            "           1       0.99      0.95      0.97       116\n",
            "\n",
            "    accuracy                           0.98       353\n",
            "   macro avg       0.98      0.97      0.98       353\n",
            "weighted avg       0.98      0.98      0.98       353\n",
            "\n",
            "Fold 5 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.99       232\n",
            "           1       0.99      0.95      0.97       120\n",
            "\n",
            "    accuracy                           0.98       352\n",
            "   macro avg       0.98      0.97      0.98       352\n",
            "weighted avg       0.98      0.98      0.98       352\n",
            "\n",
            "Average Precision across 5 folds: 0.993069237254941\n",
            "Average Accuracy across 5 folds: 0.9801587046098378\n",
            "Final Test Set Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       294\n",
            "           1       0.99      0.92      0.95       147\n",
            "\n",
            "    accuracy                           0.97       441\n",
            "   macro avg       0.98      0.96      0.97       441\n",
            "weighted avg       0.97      0.97      0.97       441\n",
            "\n",
            "Final Model Accuracy: 0.9705215419501134\n",
            "Final Model Precision: 0.9926470588235294\n",
            "Confusion Matrix - Final Model (Test Set):\n",
            "[[293   1]\n",
            " [ 12 135]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_13c7c6a2-6048-4504-89ec-9a4183b35003\", \"rf_model.pkl\", 505230)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "randomforest(X,y_stableFlag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xn6BAK2cZqr6",
        "outputId": "ced3b46d-78fa-4e23-926a-c83fbba44996"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.6143 - loss: 50.5408 - val_accuracy: 0.6232 - val_loss: 7.2022\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6407 - loss: 5.6054 - val_accuracy: 0.6232 - val_loss: 3.5394\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.7023 - loss: 3.3782 - val_accuracy: 0.4731 - val_loss: 3.1462\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6636 - loss: 2.8848 - val_accuracy: 0.7507 - val_loss: 2.5650\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7351 - loss: 2.3516 - val_accuracy: 0.6261 - val_loss: 2.0978\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7618 - loss: 2.0444 - val_accuracy: 0.6544 - val_loss: 1.9039\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8431 - loss: 1.7476 - val_accuracy: 0.8329 - val_loss: 1.8261\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8428 - loss: 1.7549 - val_accuracy: 0.8414 - val_loss: 1.7371\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8002 - loss: 1.8256 - val_accuracy: 0.8414 - val_loss: 1.6409\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8367 - loss: 1.6654 - val_accuracy: 0.8300 - val_loss: 1.4970\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8669 - loss: 1.4835 - val_accuracy: 0.8385 - val_loss: 1.4648\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8899 - loss: 1.4270 - val_accuracy: 0.8697 - val_loss: 1.4698\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8748 - loss: 1.4077 - val_accuracy: 0.8754 - val_loss: 1.4151\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8681 - loss: 1.4119 - val_accuracy: 0.8300 - val_loss: 1.4552\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8651 - loss: 1.5227 - val_accuracy: 0.6261 - val_loss: 1.5402\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8739 - loss: 1.2971 - val_accuracy: 0.6459 - val_loss: 1.8620\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8046 - loss: 1.5753 - val_accuracy: 0.9235 - val_loss: 1.2768\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9131 - loss: 1.2397 - val_accuracy: 0.8782 - val_loss: 1.3018\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8726 - loss: 1.2822 - val_accuracy: 0.7054 - val_loss: 1.8404\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8700 - loss: 1.3206 - val_accuracy: 0.8697 - val_loss: 1.3145\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8710 - loss: 1.3142 - val_accuracy: 0.8470 - val_loss: 1.2445\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8932 - loss: 1.1873 - val_accuracy: 0.7904 - val_loss: 1.3598\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7454 - loss: 1.6266 - val_accuracy: 0.8952 - val_loss: 1.3400\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8738 - loss: 1.2860 - val_accuracy: 0.9348 - val_loss: 1.1742\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9091 - loss: 1.1732 - val_accuracy: 0.8895 - val_loss: 1.2175\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8615 - loss: 1.2572 - val_accuracy: 0.8527 - val_loss: 1.2423\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8138 - loss: 1.3711 - val_accuracy: 0.8102 - val_loss: 1.3114\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8406 - loss: 1.2551 - val_accuracy: 0.7649 - val_loss: 1.4343\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8445 - loss: 1.3093 - val_accuracy: 0.6459 - val_loss: 1.3964\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
            "Fold 1:\n",
            "Validation Confusion Matrix:\n",
            "[[204  16]\n",
            " [  7 126]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.93      0.95       220\n",
            "           1       0.89      0.95      0.92       133\n",
            "\n",
            "    accuracy                           0.93       353\n",
            "   macro avg       0.93      0.94      0.93       353\n",
            "weighted avg       0.94      0.93      0.94       353\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5781 - loss: 51.4569 - val_accuracy: 0.6629 - val_loss: 8.0135\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6930 - loss: 5.9126 - val_accuracy: 0.6629 - val_loss: 3.7079\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7150 - loss: 3.3180 - val_accuracy: 0.6516 - val_loss: 2.9961\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7714 - loss: 2.6835 - val_accuracy: 0.8952 - val_loss: 2.1780\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7951 - loss: 2.1438 - val_accuracy: 0.6629 - val_loss: 2.3639\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7818 - loss: 1.9903 - val_accuracy: 0.9292 - val_loss: 1.6638\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8487 - loss: 1.7141 - val_accuracy: 0.4589 - val_loss: 2.2150\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.6178 - loss: 2.2384 - val_accuracy: 0.7960 - val_loss: 1.7124\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8178 - loss: 1.6220 - val_accuracy: 0.7762 - val_loss: 1.6189\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8126 - loss: 1.6123 - val_accuracy: 0.8074 - val_loss: 1.5167\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8402 - loss: 1.5033 - val_accuracy: 0.8357 - val_loss: 1.4289\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 23ms/step - accuracy: 0.8306 - loss: 1.4496 - val_accuracy: 0.8017 - val_loss: 1.4551\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8439 - loss: 1.4078 - val_accuracy: 0.7252 - val_loss: 1.6131\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8364 - loss: 1.4488 - val_accuracy: 0.9207 - val_loss: 1.2660\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8613 - loss: 1.3189 - val_accuracy: 0.8895 - val_loss: 1.2477\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8558 - loss: 1.3160 - val_accuracy: 0.9065 - val_loss: 1.2616\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 33ms/step - accuracy: 0.9005 - loss: 1.2618 - val_accuracy: 0.9433 - val_loss: 1.3037\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8617 - loss: 1.3156 - val_accuracy: 0.8130 - val_loss: 1.3598\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8717 - loss: 1.2789 - val_accuracy: 0.9405 - val_loss: 1.1408\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8551 - loss: 1.2560 - val_accuracy: 0.9320 - val_loss: 1.1784\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8734 - loss: 1.2428 - val_accuracy: 0.8244 - val_loss: 1.2353\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8433 - loss: 1.2877 - val_accuracy: 0.9348 - val_loss: 1.1618\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8947 - loss: 1.2259 - val_accuracy: 0.6686 - val_loss: 1.3877\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8705 - loss: 1.2445 - val_accuracy: 0.8300 - val_loss: 1.2380\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Fold 2:\n",
            "Validation Confusion Matrix:\n",
            "[[213  21]\n",
            " [  0 119]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.91      0.95       234\n",
            "           1       0.85      1.00      0.92       119\n",
            "\n",
            "    accuracy                           0.94       353\n",
            "   macro avg       0.93      0.96      0.94       353\n",
            "weighted avg       0.95      0.94      0.94       353\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.5450 - loss: 51.1785 - val_accuracy: 0.6572 - val_loss: 7.7350\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 25ms/step - accuracy: 0.6589 - loss: 5.8721 - val_accuracy: 0.8045 - val_loss: 3.7328\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.6828 - loss: 3.5141 - val_accuracy: 0.6572 - val_loss: 3.2313\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7141 - loss: 3.2584 - val_accuracy: 0.6119 - val_loss: 2.6486\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7849 - loss: 2.3922 - val_accuracy: 0.7535 - val_loss: 2.1177\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7526 - loss: 2.1638 - val_accuracy: 0.6572 - val_loss: 1.9363\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7431 - loss: 2.0045 - val_accuracy: 0.6572 - val_loss: 1.9568\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8359 - loss: 1.7464 - val_accuracy: 0.4589 - val_loss: 2.4227\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7124 - loss: 2.0015 - val_accuracy: 0.6771 - val_loss: 1.6425\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7660 - loss: 1.7012 - val_accuracy: 0.7677 - val_loss: 1.6742\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7741 - loss: 1.7330 - val_accuracy: 0.6912 - val_loss: 1.6573\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8460 - loss: 1.5175 - val_accuracy: 0.6572 - val_loss: 1.6437\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8280 - loss: 1.4869 - val_accuracy: 0.7394 - val_loss: 1.6347\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8273 - loss: 1.5387 - val_accuracy: 0.8045 - val_loss: 1.4479\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8338 - loss: 1.4140 - val_accuracy: 0.7904 - val_loss: 1.5192\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8556 - loss: 1.4222 - val_accuracy: 0.8584 - val_loss: 1.4044\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8782 - loss: 1.3503 - val_accuracy: 0.9235 - val_loss: 1.2522\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8973 - loss: 1.2659 - val_accuracy: 0.7592 - val_loss: 1.4679\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8359 - loss: 1.4371 - val_accuracy: 0.7507 - val_loss: 1.4801\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8813 - loss: 1.2888 - val_accuracy: 0.6714 - val_loss: 1.5063\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8515 - loss: 1.3238 - val_accuracy: 0.8839 - val_loss: 1.2360\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8597 - loss: 1.3001 - val_accuracy: 0.8952 - val_loss: 1.2188\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8656 - loss: 1.2564 - val_accuracy: 0.7705 - val_loss: 1.4292\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8871 - loss: 1.2523 - val_accuracy: 0.8414 - val_loss: 1.2709\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8601 - loss: 1.2429 - val_accuracy: 0.6912 - val_loss: 1.4817\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8002 - loss: 1.4228 - val_accuracy: 0.8074 - val_loss: 1.3257\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8809 - loss: 1.2256 - val_accuracy: 0.8017 - val_loss: 1.3020\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Fold 3:\n",
            "Validation Confusion Matrix:\n",
            "[[206  26]\n",
            " [ 11 110]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.89      0.92       232\n",
            "           1       0.81      0.91      0.86       121\n",
            "\n",
            "    accuracy                           0.90       353\n",
            "   macro avg       0.88      0.90      0.89       353\n",
            "weighted avg       0.90      0.90      0.90       353\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5882 - loss: 47.6297 - val_accuracy: 0.5496 - val_loss: 6.7094\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6854 - loss: 5.1889 - val_accuracy: 0.6714 - val_loss: 3.5594\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6552 - loss: 3.3574 - val_accuracy: 0.3286 - val_loss: 3.6929\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.6200 - loss: 3.1138 - val_accuracy: 0.7337 - val_loss: 2.3322\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7332 - loss: 2.2651 - val_accuracy: 0.6714 - val_loss: 2.0055\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.7620 - loss: 1.9739 - val_accuracy: 0.6714 - val_loss: 1.9919\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7742 - loss: 1.8616 - val_accuracy: 0.9178 - val_loss: 1.6070\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8652 - loss: 1.6214 - val_accuracy: 0.9093 - val_loss: 1.6156\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8440 - loss: 1.6687 - val_accuracy: 0.5921 - val_loss: 1.8978\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8059 - loss: 1.6416 - val_accuracy: 0.7535 - val_loss: 1.6832\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8054 - loss: 1.6107 - val_accuracy: 0.7705 - val_loss: 1.5877\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8121 - loss: 1.5112 - val_accuracy: 0.8499 - val_loss: 1.4059\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8737 - loss: 1.3981 - val_accuracy: 0.5609 - val_loss: 1.7939\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8378 - loss: 1.4294 - val_accuracy: 0.7394 - val_loss: 1.5664\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8269 - loss: 1.4340 - val_accuracy: 0.8272 - val_loss: 1.5146\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8186 - loss: 1.5090 - val_accuracy: 0.9235 - val_loss: 1.2341\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8895 - loss: 1.2728 - val_accuracy: 0.9037 - val_loss: 1.3149\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8959 - loss: 1.3533 - val_accuracy: 0.8697 - val_loss: 1.2765\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8173 - loss: 1.3914 - val_accuracy: 0.8045 - val_loss: 1.3914\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8686 - loss: 1.2693 - val_accuracy: 0.9008 - val_loss: 1.3347\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8218 - loss: 1.4221 - val_accuracy: 0.9150 - val_loss: 1.2100\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8912 - loss: 1.2179 - val_accuracy: 0.6799 - val_loss: 1.5257\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7964 - loss: 1.4836 - val_accuracy: 0.8924 - val_loss: 1.2372\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8887 - loss: 1.2247 - val_accuracy: 0.8980 - val_loss: 1.1676\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8301 - loss: 1.2771 - val_accuracy: 0.7280 - val_loss: 1.5453\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8326 - loss: 1.3079 - val_accuracy: 0.8839 - val_loss: 1.1808\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8595 - loss: 1.2141 - val_accuracy: 0.9292 - val_loss: 1.2726\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8337 - loss: 1.3664 - val_accuracy: 0.9263 - val_loss: 1.1468\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9087 - loss: 1.1406 - val_accuracy: 0.9235 - val_loss: 1.1298\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9107 - loss: 1.1355 - val_accuracy: 0.8782 - val_loss: 1.1515\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8563 - loss: 1.2254 - val_accuracy: 0.9320 - val_loss: 1.0853\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9333 - loss: 1.0839 - val_accuracy: 0.9320 - val_loss: 1.0639\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8659 - loss: 1.1383 - val_accuracy: 0.7365 - val_loss: 1.4117\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.7942 - loss: 1.3982 - val_accuracy: 0.9235 - val_loss: 1.1169\n",
            "Epoch 35/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8745 - loss: 1.1548 - val_accuracy: 0.8385 - val_loss: 1.2655\n",
            "Epoch 36/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8434 - loss: 1.2297 - val_accuracy: 0.9263 - val_loss: 1.0984\n",
            "Epoch 37/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8755 - loss: 1.1567 - val_accuracy: 0.9008 - val_loss: 1.0963\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Fold 4:\n",
            "Validation Confusion Matrix:\n",
            "[[221  16]\n",
            " [  8 108]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.93      0.95       237\n",
            "           1       0.87      0.93      0.90       116\n",
            "\n",
            "    accuracy                           0.93       353\n",
            "   macro avg       0.92      0.93      0.92       353\n",
            "weighted avg       0.93      0.93      0.93       353\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.5958 - loss: 51.2623 - val_accuracy: 0.6591 - val_loss: 7.0671\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6412 - loss: 5.4943 - val_accuracy: 0.6591 - val_loss: 4.3712\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7235 - loss: 3.6856 - val_accuracy: 0.6591 - val_loss: 2.9338\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7402 - loss: 2.8094 - val_accuracy: 0.6591 - val_loss: 2.4769\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7692 - loss: 2.3792 - val_accuracy: 0.8239 - val_loss: 2.0486\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8280 - loss: 2.0086 - val_accuracy: 0.7472 - val_loss: 1.9891\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7730 - loss: 1.9261 - val_accuracy: 0.8920 - val_loss: 1.9294\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.8573 - loss: 1.8300 - val_accuracy: 0.8807 - val_loss: 1.6490\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8637 - loss: 1.6535 - val_accuracy: 0.9006 - val_loss: 1.5305\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8692 - loss: 1.5421 - val_accuracy: 0.8778 - val_loss: 1.4664\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8794 - loss: 1.4644 - val_accuracy: 0.8693 - val_loss: 1.4842\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8285 - loss: 1.5303 - val_accuracy: 0.6591 - val_loss: 1.9811\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7282 - loss: 1.7959 - val_accuracy: 0.6591 - val_loss: 1.9409\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7707 - loss: 1.7581 - val_accuracy: 0.8949 - val_loss: 1.3748\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8984 - loss: 1.3481 - val_accuracy: 0.8409 - val_loss: 1.4245\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8666 - loss: 1.3692 - val_accuracy: 0.8551 - val_loss: 1.4347\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8233 - loss: 1.4511 - val_accuracy: 0.8693 - val_loss: 1.3046\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8957 - loss: 1.2684 - val_accuracy: 0.9091 - val_loss: 1.2366\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8770 - loss: 1.2715 - val_accuracy: 0.7670 - val_loss: 1.5359\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8075 - loss: 1.4585 - val_accuracy: 0.8040 - val_loss: 1.3334\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8519 - loss: 1.2900 - val_accuracy: 0.6676 - val_loss: 1.5023\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8290 - loss: 1.3572 - val_accuracy: 0.6790 - val_loss: 1.7060\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8120 - loss: 1.3868 - val_accuracy: 0.9062 - val_loss: 1.2402\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step\n",
            "Fold 5:\n",
            "Validation Confusion Matrix:\n",
            "[[202  30]\n",
            " [  2 118]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.87      0.93       232\n",
            "           1       0.80      0.98      0.88       120\n",
            "\n",
            "    accuracy                           0.91       352\n",
            "   macro avg       0.89      0.93      0.90       352\n",
            "weighted avg       0.92      0.91      0.91       352\n",
            "\n",
            "Average Accuracy across all folds: 0.9223\n",
            "Average Precision across all folds: 0.9292\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.5796 - loss: 49.5427 - val_accuracy: 0.6686 - val_loss: 7.6084\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 16ms/step - accuracy: 0.6656 - loss: 5.7789 - val_accuracy: 0.7904 - val_loss: 3.5867\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7716 - loss: 3.4492 - val_accuracy: 0.3796 - val_loss: 3.5285\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7201 - loss: 3.1509 - val_accuracy: 0.6686 - val_loss: 2.9802\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7498 - loss: 2.6824 - val_accuracy: 0.8215 - val_loss: 2.3791\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7989 - loss: 2.3045 - val_accuracy: 0.6686 - val_loss: 2.3153\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7891 - loss: 2.1915 - val_accuracy: 0.8555 - val_loss: 1.8212\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8376 - loss: 1.8945 - val_accuracy: 0.6431 - val_loss: 2.4363\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7886 - loss: 2.0486 - val_accuracy: 0.6686 - val_loss: 2.1158\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7816 - loss: 1.9009 - val_accuracy: 0.9235 - val_loss: 1.5770\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8544 - loss: 1.6582 - val_accuracy: 0.8640 - val_loss: 1.6286\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.8813 - loss: 1.5604 - val_accuracy: 0.8300 - val_loss: 1.5240\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8572 - loss: 1.5114 - val_accuracy: 0.8584 - val_loss: 1.4077\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8456 - loss: 1.4831 - val_accuracy: 0.8442 - val_loss: 1.4775\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8557 - loss: 1.4391 - val_accuracy: 0.7337 - val_loss: 1.6867\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8356 - loss: 1.5094 - val_accuracy: 0.8924 - val_loss: 1.3633\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8671 - loss: 1.4034 - val_accuracy: 0.6657 - val_loss: 1.7424\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8422 - loss: 1.4657 - val_accuracy: 0.8612 - val_loss: 1.3391\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8504 - loss: 1.3431 - val_accuracy: 0.8640 - val_loss: 1.3198\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8630 - loss: 1.3331 - val_accuracy: 0.8725 - val_loss: 1.2453\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8610 - loss: 1.3287 - val_accuracy: 0.9122 - val_loss: 1.2554\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8583 - loss: 1.2894 - val_accuracy: 0.8045 - val_loss: 1.3839\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8468 - loss: 1.3478 - val_accuracy: 0.8584 - val_loss: 1.2244\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9034 - loss: 1.2054 - val_accuracy: 0.9405 - val_loss: 1.1867\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8768 - loss: 1.2313 - val_accuracy: 0.6941 - val_loss: 1.6245\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.6404 - loss: 1.7034 - val_accuracy: 0.9292 - val_loss: 1.1842\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8779 - loss: 1.2637 - val_accuracy: 0.8017 - val_loss: 1.4257\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8655 - loss: 1.2798 - val_accuracy: 0.6686 - val_loss: 1.5262\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8172 - loss: 1.3130 - val_accuracy: 0.9207 - val_loss: 1.1805\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8797 - loss: 1.2047 - val_accuracy: 0.9263 - val_loss: 1.1315\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8809 - loss: 1.1922 - val_accuracy: 0.7337 - val_loss: 1.3035\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8456 - loss: 1.2268 - val_accuracy: 0.9320 - val_loss: 1.0999\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8752 - loss: 1.1662 - val_accuracy: 0.8527 - val_loss: 1.2028\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8830 - loss: 1.1741 - val_accuracy: 0.8612 - val_loss: 1.1518\n",
            "Epoch 35/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8764 - loss: 1.1928 - val_accuracy: 0.9122 - val_loss: 1.1346\n",
            "Epoch 36/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8611 - loss: 1.2047 - val_accuracy: 0.9518 - val_loss: 1.0940\n",
            "Epoch 37/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8972 - loss: 1.1376 - val_accuracy: 0.8754 - val_loss: 1.1459\n",
            "Epoch 38/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9056 - loss: 1.1351 - val_accuracy: 0.9377 - val_loss: 1.0810\n",
            "Epoch 39/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8929 - loss: 1.1408 - val_accuracy: 0.8442 - val_loss: 1.2576\n",
            "Epoch 40/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8987 - loss: 1.1387 - val_accuracy: 0.9235 - val_loss: 1.0758\n",
            "Epoch 41/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.8189 - loss: 1.2146 - val_accuracy: 0.8895 - val_loss: 1.0957\n",
            "Epoch 42/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8993 - loss: 1.0986 - val_accuracy: 0.9207 - val_loss: 1.0755\n",
            "Epoch 43/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.8947 - loss: 1.1084 - val_accuracy: 0.8584 - val_loss: 1.1342\n",
            "Epoch 44/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.8866 - loss: 1.1348 - val_accuracy: 0.8017 - val_loss: 1.2180\n",
            "Epoch 45/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.8972 - loss: 1.1044 - val_accuracy: 0.8810 - val_loss: 1.1072\n",
            "Epoch 46/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8815 - loss: 1.1194 - val_accuracy: 0.8215 - val_loss: 1.2242\n",
            "Epoch 47/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8793 - loss: 1.1319 - val_accuracy: 0.9462 - val_loss: 1.0379\n",
            "Epoch 48/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8819 - loss: 1.1357 - val_accuracy: 0.6856 - val_loss: 1.3519\n",
            "Epoch 49/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8330 - loss: 1.1865 - val_accuracy: 0.9178 - val_loss: 1.0555\n",
            "Epoch 50/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8328 - loss: 1.2040 - val_accuracy: 0.9037 - val_loss: 1.1001\n",
            "Epoch 51/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8944 - loss: 1.1111 - val_accuracy: 0.9008 - val_loss: 1.0739\n",
            "Epoch 52/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8678 - loss: 1.1460 - val_accuracy: 0.7167 - val_loss: 1.4320\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\n",
            "Final Model Evaluation on Test Set:\n",
            "Confusion Matrix:\n",
            "[[281  13]\n",
            " [ 15 132]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.96      0.95       294\n",
            "           1       0.91      0.90      0.90       147\n",
            "\n",
            "    accuracy                           0.94       441\n",
            "   macro avg       0.93      0.93      0.93       441\n",
            "weighted avg       0.94      0.94      0.94       441\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4b6ab27f-4de8-443b-8ed7-8042809fac8d\", \"nn_model.pkl\", 7881754)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "neuralnetwork(X,y_stableFlag)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2BQvuptSaZbA"
      },
      "source": [
        "# Approach 3 - Mean of a cycle for each sensor value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "jsFmUioE5wZy"
      },
      "outputs": [],
      "source": [
        "PS1 = pd.DataFrame(mean_conversion(pressureFile1))\n",
        "PS1.columns = ['PS1'] # Rename the column to 'PS1'\n",
        "\n",
        "PS2 = pd.DataFrame(mean_conversion(pressureFile2))\n",
        "PS2.columns = ['PS2']\n",
        "\n",
        "PS3 = pd.DataFrame(mean_conversion(pressureFile3))\n",
        "PS3.columns = ['PS3']\n",
        "\n",
        "PS4 = pd.DataFrame(mean_conversion(pressureFile4))\n",
        "PS4.columns = ['PS4']\n",
        "\n",
        "PS5 = pd.DataFrame(mean_conversion(pressureFile5))\n",
        "PS5.columns = ['PS5']\n",
        "\n",
        "PS6 = pd.DataFrame(mean_conversion(pressureFile6))\n",
        "PS6.columns = ['PS6']\n",
        "\n",
        "FS1 = pd.DataFrame(mean_conversion(volumeFlow1))\n",
        "FS1.columns = ['FS1']\n",
        "\n",
        "FS2 = pd.DataFrame(mean_conversion(volumeFlow2))\n",
        "FS2.columns = ['FS2']\n",
        "\n",
        "TS1 = pd.DataFrame(mean_conversion(temperature1))\n",
        "TS1.columns = ['TS1']\n",
        "\n",
        "TS2 = pd.DataFrame(mean_conversion(temperature2))\n",
        "TS2.columns = ['TS2']\n",
        "\n",
        "TS3 = pd.DataFrame(mean_conversion(temperature3))\n",
        "TS3.columns = ['TS3']\n",
        "\n",
        "TS4 = pd.DataFrame(mean_conversion(temperature4))\n",
        "TS4.columns = ['TS4']\n",
        "\n",
        "P1 = pd.DataFrame(mean_conversion(pump1))\n",
        "P1.columns = ['P1']\n",
        "\n",
        "VS1 = pd.DataFrame(mean_conversion(vibration1))\n",
        "VS1.columns = ['VS1']\n",
        "\n",
        "CE1 = pd.DataFrame(mean_conversion(coolingE1))\n",
        "CE1.columns = ['CE1']\n",
        "\n",
        "CP1 = pd.DataFrame(mean_conversion(coolingP1))\n",
        "CP1.columns = ['CP1']\n",
        "\n",
        "SE1 = pd.DataFrame(mean_conversion(effFactor1))\n",
        "SE1.columns = ['SE1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3YzCV2iakDz",
        "outputId": "738b2164-833b-4f79-c764-e098ae5fef07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n",
            "(2205, 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25726"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "print(PS1.shape)\n",
        "print(PS2.shape)\n",
        "print(PS3.shape)\n",
        "print(PS4.shape)\n",
        "print(PS5.shape)\n",
        "print(PS6.shape)\n",
        "print(P1.shape)\n",
        "print(FS1.shape)\n",
        "print(FS2.shape)\n",
        "print(TS1.shape)\n",
        "print(TS2.shape)\n",
        "print(TS3.shape)\n",
        "print(TS4.shape)\n",
        "print(VS1.shape)\n",
        "print(CE1.shape)\n",
        "print(CP1.shape)\n",
        "print(SE1.shape)\n",
        "\n",
        "X = pd.concat([PS1, PS2, PS3, PS4, PS5, PS6, FS1, FS2, TS1, TS2, TS3, TS4, P1, VS1, CE1, CP1, SE1], axis=1)\n",
        "# del PS1, PS2, PS3, PS4, PS5, PS6, pressureFile3, pressureFile4, pressureFile5, pressureFile6, pressureFile1, pressureFile2, FS1, FS2, volumeFlow1, volumeFlow2\n",
        "# del temperature1, temperature2, temperature3, temperature4, pump1, vibration1, coolingE1, coolingP1, effFactor1\n",
        "# del profile, TS1, TS2, TS3, TS4, P1, VS1, CE1, CP1, SE1\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-dCCxt2ap_Q",
        "outputId": "a6f500ea-91de-49cc-8e0b-fee9acc44f8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2205, 17)\n"
          ]
        }
      ],
      "source": [
        "scaler = MinMaxScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X = pd.DataFrame(X)\n",
        "print(X.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4Dqqux-Sa3UJ",
        "outputId": "8f81f3a9-fc6b-4fa5-8801-5943c1ede4a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98       310\n",
            "           1       0.98      0.90      0.94       131\n",
            "\n",
            "    accuracy                           0.97       441\n",
            "   macro avg       0.97      0.95      0.96       441\n",
            "weighted avg       0.97      0.97      0.97       441\n",
            "\n",
            "Fold 1 F1-score: 0.9655\n",
            "Fold 1 Accuracy: 0.9660\n",
            "Fold 1 Precision: 0.9666\n",
            "Confusion Matrix:\n",
            "[[308   2]\n",
            " [ 13 118]]\n",
            "------------------------------\n",
            "Fold 2:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       277\n",
            "           1       0.99      0.91      0.95       164\n",
            "\n",
            "    accuracy                           0.97       441\n",
            "   macro avg       0.97      0.96      0.96       441\n",
            "weighted avg       0.97      0.97      0.97       441\n",
            "\n",
            "Fold 2 F1-score: 0.9657\n",
            "Fold 2 Accuracy: 0.9660\n",
            "Fold 2 Precision: 0.9672\n",
            "Confusion Matrix:\n",
            "[[276   1]\n",
            " [ 14 150]]\n",
            "------------------------------\n",
            "Fold 3:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       281\n",
            "           1       0.99      0.95      0.97       160\n",
            "\n",
            "    accuracy                           0.98       441\n",
            "   macro avg       0.98      0.97      0.98       441\n",
            "weighted avg       0.98      0.98      0.98       441\n",
            "\n",
            "Fold 3 F1-score: 0.9795\n",
            "Fold 3 Accuracy: 0.9796\n",
            "Fold 3 Precision: 0.9799\n",
            "Confusion Matrix:\n",
            "[[280   1]\n",
            " [  8 152]]\n",
            "------------------------------\n",
            "Fold 4:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      0.99      0.98       278\n",
            "           1       0.99      0.93      0.96       163\n",
            "\n",
            "    accuracy                           0.97       441\n",
            "   macro avg       0.97      0.96      0.97       441\n",
            "weighted avg       0.97      0.97      0.97       441\n",
            "\n",
            "Fold 4 F1-score: 0.9680\n",
            "Fold 4 Accuracy: 0.9683\n",
            "Fold 4 Precision: 0.9689\n",
            "Confusion Matrix:\n",
            "[[276   2]\n",
            " [ 12 151]]\n",
            "------------------------------\n",
            "Fold 5:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.99      0.97       303\n",
            "           1       0.98      0.88      0.93       138\n",
            "\n",
            "    accuracy                           0.96       441\n",
            "   macro avg       0.96      0.94      0.95       441\n",
            "weighted avg       0.96      0.96      0.96       441\n",
            "\n",
            "Fold 5 F1-score: 0.9563\n",
            "Fold 5 Accuracy: 0.9569\n",
            "Fold 5 Precision: 0.9577\n",
            "Confusion Matrix:\n",
            "[[300   3]\n",
            " [ 16 122]]\n",
            "------------------------------\n",
            "Average F1-score across 5 folds: 0.9670\n",
            "Average Accuracy across 5 folds: 0.9673\n",
            "Average Precision across 5 folds: 0.9681\n",
            "Training final model on the entire dataset...\n",
            "Final Model Accuracy: 0.9660\n",
            "Final Model Precision: 0.9671\n",
            "Final Model Confusion Matrix:\n",
            "[[293   1]\n",
            " [ 14 133]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_172ba1f8-cd82-4d27-a44a-79874b0ddc0b\", \"XGB_final_model.pkl\", 98594)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "xgb_(X, y_stableFlag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bP1Oh3zIbA0b",
        "outputId": "20333860-71e6-4ae5-f847-7a6a64e8eb1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.98       220\n",
            "           1       1.00      0.92      0.96       133\n",
            "\n",
            "    accuracy                           0.97       353\n",
            "   macro avg       0.98      0.96      0.97       353\n",
            "weighted avg       0.97      0.97      0.97       353\n",
            "\n",
            "Fold 2 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      1.00      0.98       234\n",
            "           1       0.99      0.94      0.97       119\n",
            "\n",
            "    accuracy                           0.98       353\n",
            "   macro avg       0.98      0.97      0.97       353\n",
            "weighted avg       0.98      0.98      0.98       353\n",
            "\n",
            "Fold 3 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       232\n",
            "           1       0.99      0.90      0.94       121\n",
            "\n",
            "    accuracy                           0.96       353\n",
            "   macro avg       0.97      0.95      0.96       353\n",
            "weighted avg       0.96      0.96      0.96       353\n",
            "\n",
            "Fold 4 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       237\n",
            "           1       1.00      0.91      0.95       116\n",
            "\n",
            "    accuracy                           0.97       353\n",
            "   macro avg       0.98      0.95      0.96       353\n",
            "weighted avg       0.97      0.97      0.97       353\n",
            "\n",
            "Fold 5 Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      1.00      0.97       232\n",
            "           1       0.99      0.89      0.94       120\n",
            "\n",
            "    accuracy                           0.96       352\n",
            "   macro avg       0.97      0.94      0.95       352\n",
            "weighted avg       0.96      0.96      0.96       352\n",
            "\n",
            "Average Precision across 5 folds: 0.9945600548255416\n",
            "Average Accuracy across 5 folds: 0.9676828483131599\n",
            "Final Test Set Evaluation:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.96      1.00      0.98       294\n",
            "           1       1.00      0.91      0.95       147\n",
            "\n",
            "    accuracy                           0.97       441\n",
            "   macro avg       0.98      0.96      0.97       441\n",
            "weighted avg       0.97      0.97      0.97       441\n",
            "\n",
            "Final Model Accuracy: 0.9705215419501134\n",
            "Final Model Precision: 1.0\n",
            "Confusion Matrix - Final Model (Test Set):\n",
            "[[294   0]\n",
            " [ 13 134]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8127b799-6fc7-4ecc-9936-292fa3f5168f\", \"rf_model.pkl\", 634327)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "randomforest(X,y_stableFlag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "id": "T9UMJqt-bCpX",
        "outputId": "3de648d8-562e-4506-9fad-921f4717db54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision scores for each fold: [0.9565217391304348, 1.0, 0.9393939393939394, 0.90625, 0.96]\n",
            "Average precision: 0.9524331357048748\n",
            "Average accuracy: 0.7290925902576388\n",
            "Confusion matrix for training set:\n",
            " [[996   7]\n",
            " [411 129]]\n",
            "Test set accuracy: 0.7507552870090635\n",
            "Test set precision: 0.9180327868852459\n",
            "Test set confusion matrix:\n",
            " [[441   5]\n",
            " [160  56]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_2df3bff2-97c7-4a0c-b79f-888e03e91ee3\", \"svm_model.pkl\", 154559)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "svm(X,y_stableFlag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "paqFYpbzbElH",
        "outputId": "8d2d51f9-ce88-4c5a-9af8-65da4bb295ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.5616 - loss: 5.3362 - val_accuracy: 0.6232 - val_loss: 4.1475\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6626 - loss: 3.8213 - val_accuracy: 0.6232 - val_loss: 3.0020\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6545 - loss: 2.7516 - val_accuracy: 0.6232 - val_loss: 2.1332\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6691 - loss: 1.9323 - val_accuracy: 0.6232 - val_loss: 1.4965\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6722 - loss: 1.3595 - val_accuracy: 0.6232 - val_loss: 1.0927\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6435 - loss: 1.0177 - val_accuracy: 0.6232 - val_loss: 0.8880\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6846 - loss: 0.8230 - val_accuracy: 0.6232 - val_loss: 0.8043\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6629 - loss: 0.7692 - val_accuracy: 0.6232 - val_loss: 0.7668\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6281 - loss: 0.7574 - val_accuracy: 0.6232 - val_loss: 0.7458\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6707 - loss: 0.7073 - val_accuracy: 0.6232 - val_loss: 0.7260\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6689 - loss: 0.6931 - val_accuracy: 0.6232 - val_loss: 0.7162\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6885 - loss: 0.6689 - val_accuracy: 0.6232 - val_loss: 0.7040\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6656 - loss: 0.6770 - val_accuracy: 0.6232 - val_loss: 0.6976\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6856 - loss: 0.6557 - val_accuracy: 0.6232 - val_loss: 0.6908\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6420 - loss: 0.6790 - val_accuracy: 0.6232 - val_loss: 0.6871\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6658 - loss: 0.6582 - val_accuracy: 0.6232 - val_loss: 0.6838\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6689 - loss: 0.6517 - val_accuracy: 0.6232 - val_loss: 0.6804\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6510 - loss: 0.6616 - val_accuracy: 0.6232 - val_loss: 0.6788\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6616 - loss: 0.6527 - val_accuracy: 0.6232 - val_loss: 0.6781\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6412 - loss: 0.6659 - val_accuracy: 0.6232 - val_loss: 0.6767\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6651 - loss: 0.6477 - val_accuracy: 0.6232 - val_loss: 0.6758\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6711 - loss: 0.6427 - val_accuracy: 0.6232 - val_loss: 0.6743\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6624 - loss: 0.6475 - val_accuracy: 0.6232 - val_loss: 0.6727\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6663 - loss: 0.6443 - val_accuracy: 0.6232 - val_loss: 0.6723\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6656 - loss: 0.6440 - val_accuracy: 0.6232 - val_loss: 0.6716\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6593 - loss: 0.6479 - val_accuracy: 0.6232 - val_loss: 0.6722\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6611 - loss: 0.6464 - val_accuracy: 0.6232 - val_loss: 0.6703\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6542 - loss: 0.6505 - val_accuracy: 0.6232 - val_loss: 0.6703\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6553 - loss: 0.6493 - val_accuracy: 0.6232 - val_loss: 0.6711\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6579 - loss: 0.6476 - val_accuracy: 0.6232 - val_loss: 0.6717\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6917 - loss: 0.6235 - val_accuracy: 0.6232 - val_loss: 0.6706\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6620 - loss: 0.6456 - val_accuracy: 0.6232 - val_loss: 0.6707\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
            "Fold 1:\n",
            "Validation Confusion Matrix:\n",
            "[[220   0]\n",
            " [133   0]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      1.00      0.77       220\n",
            "           1       0.00      0.00      0.00       133\n",
            "\n",
            "    accuracy                           0.62       353\n",
            "   macro avg       0.31      0.50      0.38       353\n",
            "weighted avg       0.39      0.62      0.48       353\n",
            "\n",
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step - accuracy: 0.4986 - loss: 5.3759 - val_accuracy: 0.6629 - val_loss: 4.1677\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6583 - loss: 3.8586 - val_accuracy: 0.6629 - val_loss: 3.0136\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6341 - loss: 2.7988 - val_accuracy: 0.6629 - val_loss: 2.1586\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6661 - loss: 1.9900 - val_accuracy: 0.6629 - val_loss: 1.5483\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6456 - loss: 1.4464 - val_accuracy: 0.6629 - val_loss: 1.1478\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6551 - loss: 1.0893 - val_accuracy: 0.6629 - val_loss: 0.9225\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6421 - loss: 0.9055 - val_accuracy: 0.6629 - val_loss: 0.8216\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6512 - loss: 0.8147 - val_accuracy: 0.6629 - val_loss: 0.7670\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6481 - loss: 0.7674 - val_accuracy: 0.6629 - val_loss: 0.7318\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6787 - loss: 0.7156 - val_accuracy: 0.6629 - val_loss: 0.7092\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6558 - loss: 0.7101 - val_accuracy: 0.6629 - val_loss: 0.6912\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6474 - loss: 0.7007 - val_accuracy: 0.6629 - val_loss: 0.6803\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6476 - loss: 0.6871 - val_accuracy: 0.6629 - val_loss: 0.6709\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6621 - loss: 0.6722 - val_accuracy: 0.6629 - val_loss: 0.6624\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6438 - loss: 0.6738 - val_accuracy: 0.6629 - val_loss: 0.6545\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6522 - loss: 0.6641 - val_accuracy: 0.6629 - val_loss: 0.6494\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6441 - loss: 0.6676 - val_accuracy: 0.6629 - val_loss: 0.6427\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6458 - loss: 0.6531 - val_accuracy: 0.6629 - val_loss: 0.6354\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6546 - loss: 0.6471 - val_accuracy: 0.6629 - val_loss: 0.6296\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6257 - loss: 0.6580 - val_accuracy: 0.6629 - val_loss: 0.6263\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6732 - loss: 0.6313 - val_accuracy: 0.6629 - val_loss: 0.6265\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6737 - loss: 0.6351 - val_accuracy: 0.6629 - val_loss: 0.6150\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6554 - loss: 0.6338 - val_accuracy: 0.6629 - val_loss: 0.6108\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6733 - loss: 0.6261 - val_accuracy: 0.6629 - val_loss: 0.6059\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6849 - loss: 0.6239 - val_accuracy: 0.6629 - val_loss: 0.6019\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6659 - loss: 0.6172 - val_accuracy: 0.7025 - val_loss: 0.5984\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6689 - loss: 0.6154 - val_accuracy: 0.7224 - val_loss: 0.5967\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6917 - loss: 0.6154 - val_accuracy: 0.6629 - val_loss: 0.5989\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6709 - loss: 0.6188 - val_accuracy: 0.7224 - val_loss: 0.5921\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7112 - loss: 0.6101 - val_accuracy: 0.7224 - val_loss: 0.5910\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6654 - loss: 0.6322 - val_accuracy: 0.7224 - val_loss: 0.5878\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6967 - loss: 0.6000 - val_accuracy: 0.7224 - val_loss: 0.5853\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6879 - loss: 0.6131 - val_accuracy: 0.7252 - val_loss: 0.5837\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6973 - loss: 0.6126 - val_accuracy: 0.7252 - val_loss: 0.5825\n",
            "Epoch 35/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7076 - loss: 0.6088 - val_accuracy: 0.6544 - val_loss: 0.5880\n",
            "Epoch 36/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7108 - loss: 0.6029 - val_accuracy: 0.7224 - val_loss: 0.5800\n",
            "Epoch 37/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6890 - loss: 0.6205 - val_accuracy: 0.7224 - val_loss: 0.5791\n",
            "Epoch 38/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7060 - loss: 0.5981 - val_accuracy: 0.7337 - val_loss: 0.5764\n",
            "Epoch 39/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7092 - loss: 0.5969 - val_accuracy: 0.7252 - val_loss: 0.5760\n",
            "Epoch 40/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6949 - loss: 0.6095 - val_accuracy: 0.7252 - val_loss: 0.5765\n",
            "Epoch 41/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7227 - loss: 0.6017 - val_accuracy: 0.7365 - val_loss: 0.5741\n",
            "Epoch 42/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6660 - loss: 0.6209 - val_accuracy: 0.7309 - val_loss: 0.5740\n",
            "Epoch 43/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6990 - loss: 0.6004 - val_accuracy: 0.7280 - val_loss: 0.5704\n",
            "Epoch 44/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7053 - loss: 0.6148 - val_accuracy: 0.7365 - val_loss: 0.5716\n",
            "Epoch 45/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7156 - loss: 0.5991 - val_accuracy: 0.7309 - val_loss: 0.5689\n",
            "Epoch 46/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7198 - loss: 0.5842 - val_accuracy: 0.7620 - val_loss: 0.5678\n",
            "Epoch 47/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7246 - loss: 0.5974 - val_accuracy: 0.7309 - val_loss: 0.5663\n",
            "Epoch 48/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7065 - loss: 0.5883 - val_accuracy: 0.7224 - val_loss: 0.5655\n",
            "Epoch 49/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7274 - loss: 0.5885 - val_accuracy: 0.7280 - val_loss: 0.5654\n",
            "Epoch 50/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6988 - loss: 0.6062 - val_accuracy: 0.7280 - val_loss: 0.5660\n",
            "Epoch 51/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7011 - loss: 0.5991 - val_accuracy: 0.7280 - val_loss: 0.5639\n",
            "Epoch 52/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7218 - loss: 0.5887 - val_accuracy: 0.7365 - val_loss: 0.5614\n",
            "Epoch 53/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7273 - loss: 0.5829 - val_accuracy: 0.7620 - val_loss: 0.5614\n",
            "Epoch 54/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7088 - loss: 0.5855 - val_accuracy: 0.7252 - val_loss: 0.5626\n",
            "Epoch 55/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7279 - loss: 0.5804 - val_accuracy: 0.7790 - val_loss: 0.5594\n",
            "Epoch 56/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7670 - loss: 0.5760 - val_accuracy: 0.6572 - val_loss: 0.5657\n",
            "Epoch 57/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7194 - loss: 0.5869 - val_accuracy: 0.7649 - val_loss: 0.5583\n",
            "Epoch 58/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7433 - loss: 0.5759 - val_accuracy: 0.7252 - val_loss: 0.5580\n",
            "Epoch 59/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7465 - loss: 0.5705 - val_accuracy: 0.7280 - val_loss: 0.5585\n",
            "Epoch 60/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6985 - loss: 0.6026 - val_accuracy: 0.7649 - val_loss: 0.5553\n",
            "Epoch 61/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7684 - loss: 0.5790 - val_accuracy: 0.7592 - val_loss: 0.5547\n",
            "Epoch 62/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7534 - loss: 0.5878 - val_accuracy: 0.7620 - val_loss: 0.5539\n",
            "Epoch 63/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7321 - loss: 0.5769 - val_accuracy: 0.7365 - val_loss: 0.5542\n",
            "Epoch 64/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7406 - loss: 0.5761 - val_accuracy: 0.7620 - val_loss: 0.5530\n",
            "Epoch 65/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7559 - loss: 0.5934 - val_accuracy: 0.7819 - val_loss: 0.5530\n",
            "Epoch 66/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7285 - loss: 0.5926 - val_accuracy: 0.7649 - val_loss: 0.5528\n",
            "Epoch 67/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.7427 - loss: 0.5843 - val_accuracy: 0.7252 - val_loss: 0.5547\n",
            "Epoch 68/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7229 - loss: 0.5739 - val_accuracy: 0.7620 - val_loss: 0.5525\n",
            "Epoch 69/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7453 - loss: 0.5786 - val_accuracy: 0.7734 - val_loss: 0.5506\n",
            "Epoch 70/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7758 - loss: 0.5709 - val_accuracy: 0.7762 - val_loss: 0.5498\n",
            "Epoch 71/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7517 - loss: 0.5749 - val_accuracy: 0.6799 - val_loss: 0.5539\n",
            "Epoch 72/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7049 - loss: 0.5823 - val_accuracy: 0.7564 - val_loss: 0.5488\n",
            "Epoch 73/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5596 - val_accuracy: 0.7875 - val_loss: 0.5487\n",
            "Epoch 74/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5993 - val_accuracy: 0.7705 - val_loss: 0.5480\n",
            "Epoch 75/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7648 - loss: 0.5846 - val_accuracy: 0.7564 - val_loss: 0.5504\n",
            "Epoch 76/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7481 - loss: 0.5735 - val_accuracy: 0.7280 - val_loss: 0.5503\n",
            "Epoch 77/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7209 - loss: 0.5693 - val_accuracy: 0.7734 - val_loss: 0.5469\n",
            "Epoch 78/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7485 - loss: 0.5815 - val_accuracy: 0.6856 - val_loss: 0.5515\n",
            "Epoch 79/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5863 - val_accuracy: 0.7734 - val_loss: 0.5456\n",
            "Epoch 80/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7807 - loss: 0.5717 - val_accuracy: 0.7847 - val_loss: 0.5453\n",
            "Epoch 81/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7834 - loss: 0.5714 - val_accuracy: 0.7734 - val_loss: 0.5459\n",
            "Epoch 82/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7598 - loss: 0.5839 - val_accuracy: 0.7819 - val_loss: 0.5441\n",
            "Epoch 83/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7592 - loss: 0.5834 - val_accuracy: 0.7819 - val_loss: 0.5444\n",
            "Epoch 84/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7752 - loss: 0.5629 - val_accuracy: 0.7790 - val_loss: 0.5441\n",
            "Epoch 85/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7698 - loss: 0.5649 - val_accuracy: 0.7819 - val_loss: 0.5428\n",
            "Epoch 86/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7588 - loss: 0.5667 - val_accuracy: 0.7847 - val_loss: 0.5433\n",
            "Epoch 87/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7729 - loss: 0.5714 - val_accuracy: 0.7620 - val_loss: 0.5435\n",
            "Epoch 88/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7673 - loss: 0.5763 - val_accuracy: 0.7819 - val_loss: 0.5416\n",
            "Epoch 89/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7499 - loss: 0.5871 - val_accuracy: 0.7705 - val_loss: 0.5430\n",
            "Epoch 90/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7548 - loss: 0.5900 - val_accuracy: 0.7649 - val_loss: 0.5417\n",
            "Epoch 91/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7462 - loss: 0.5843 - val_accuracy: 0.7677 - val_loss: 0.5433\n",
            "Epoch 92/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7497 - loss: 0.5836 - val_accuracy: 0.7875 - val_loss: 0.5401\n",
            "Epoch 93/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7619 - loss: 0.5833 - val_accuracy: 0.7819 - val_loss: 0.5399\n",
            "Epoch 94/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7294 - loss: 0.5752 - val_accuracy: 0.7790 - val_loss: 0.5390\n",
            "Epoch 95/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7580 - loss: 0.5723 - val_accuracy: 0.7819 - val_loss: 0.5382\n",
            "Epoch 96/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7875 - loss: 0.5600 - val_accuracy: 0.7875 - val_loss: 0.5387\n",
            "Epoch 97/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7689 - loss: 0.5631 - val_accuracy: 0.7790 - val_loss: 0.5381\n",
            "Epoch 98/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7642 - loss: 0.5794 - val_accuracy: 0.7875 - val_loss: 0.5384\n",
            "Epoch 99/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7709 - loss: 0.5803 - val_accuracy: 0.7620 - val_loss: 0.5400\n",
            "Epoch 100/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7594 - loss: 0.5844 - val_accuracy: 0.7819 - val_loss: 0.5378\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Fold 2:\n",
            "Validation Confusion Matrix:\n",
            "[[223  11]\n",
            " [ 66  53]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.95      0.85       234\n",
            "           1       0.83      0.45      0.58       119\n",
            "\n",
            "    accuracy                           0.78       353\n",
            "   macro avg       0.80      0.70      0.72       353\n",
            "weighted avg       0.79      0.78      0.76       353\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5036 - loss: 5.3991 - val_accuracy: 0.6572 - val_loss: 4.1324\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6316 - loss: 3.8383 - val_accuracy: 0.6572 - val_loss: 2.9836\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6423 - loss: 2.7638 - val_accuracy: 0.6572 - val_loss: 2.1453\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6477 - loss: 1.9843 - val_accuracy: 0.6572 - val_loss: 1.5447\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6496 - loss: 1.4373 - val_accuracy: 0.6572 - val_loss: 1.1509\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6550 - loss: 1.0895 - val_accuracy: 0.6572 - val_loss: 0.9452\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6642 - loss: 0.9133 - val_accuracy: 0.6572 - val_loss: 0.8563\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6732 - loss: 0.8324 - val_accuracy: 0.6572 - val_loss: 0.8012\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6665 - loss: 0.7878 - val_accuracy: 0.6572 - val_loss: 0.7656\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6760 - loss: 0.7462 - val_accuracy: 0.6572 - val_loss: 0.7408\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6484 - loss: 0.7401 - val_accuracy: 0.6572 - val_loss: 0.7199\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6602 - loss: 0.7131 - val_accuracy: 0.6572 - val_loss: 0.7048\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6303 - loss: 0.7168 - val_accuracy: 0.6572 - val_loss: 0.6927\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6663 - loss: 0.6838 - val_accuracy: 0.6572 - val_loss: 0.6838\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6573 - loss: 0.6812 - val_accuracy: 0.6572 - val_loss: 0.6769\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6531 - loss: 0.6770 - val_accuracy: 0.6572 - val_loss: 0.6718\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6434 - loss: 0.6790 - val_accuracy: 0.6572 - val_loss: 0.6682\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6528 - loss: 0.6698 - val_accuracy: 0.6572 - val_loss: 0.6650\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6579 - loss: 0.6643 - val_accuracy: 0.6572 - val_loss: 0.6633\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6800 - loss: 0.6493 - val_accuracy: 0.6572 - val_loss: 0.6617\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6705 - loss: 0.6542 - val_accuracy: 0.6572 - val_loss: 0.6605\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6256 - loss: 0.6787 - val_accuracy: 0.6572 - val_loss: 0.6598\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6624 - loss: 0.6553 - val_accuracy: 0.6572 - val_loss: 0.6585\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6333 - loss: 0.6731 - val_accuracy: 0.6572 - val_loss: 0.6582\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6507 - loss: 0.6615 - val_accuracy: 0.6572 - val_loss: 0.6574\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6728 - loss: 0.6468 - val_accuracy: 0.6572 - val_loss: 0.6570\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6446 - loss: 0.6632 - val_accuracy: 0.6572 - val_loss: 0.6570\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6307 - loss: 0.6740 - val_accuracy: 0.6572 - val_loss: 0.6562\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6497 - loss: 0.6609 - val_accuracy: 0.6572 - val_loss: 0.6551\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6547 - loss: 0.6549 - val_accuracy: 0.6572 - val_loss: 0.6543\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6552 - loss: 0.6547 - val_accuracy: 0.6572 - val_loss: 0.6538\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6560 - loss: 0.6525 - val_accuracy: 0.6572 - val_loss: 0.6531\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6416 - loss: 0.6585 - val_accuracy: 0.6572 - val_loss: 0.6509\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6577 - loss: 0.6491 - val_accuracy: 0.6572 - val_loss: 0.6467\n",
            "Epoch 35/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6551 - loss: 0.6410 - val_accuracy: 0.6572 - val_loss: 0.6432\n",
            "Epoch 36/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6441 - loss: 0.6466 - val_accuracy: 0.6572 - val_loss: 0.6385\n",
            "Epoch 37/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6520 - loss: 0.6304 - val_accuracy: 0.6572 - val_loss: 0.6333\n",
            "Epoch 38/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6497 - loss: 0.6361 - val_accuracy: 0.6572 - val_loss: 0.6293\n",
            "Epoch 39/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6346 - loss: 0.6348 - val_accuracy: 0.6572 - val_loss: 0.6252\n",
            "Epoch 40/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6600 - loss: 0.6103 - val_accuracy: 0.6572 - val_loss: 0.6210\n",
            "Epoch 41/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6574 - loss: 0.6019 - val_accuracy: 0.6997 - val_loss: 0.6204\n",
            "Epoch 42/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7161 - loss: 0.6103 - val_accuracy: 0.6827 - val_loss: 0.6151\n",
            "Epoch 43/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6643 - loss: 0.6101 - val_accuracy: 0.6601 - val_loss: 0.6127\n",
            "Epoch 44/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6718 - loss: 0.6076 - val_accuracy: 0.7082 - val_loss: 0.6089\n",
            "Epoch 45/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6885 - loss: 0.6062 - val_accuracy: 0.6969 - val_loss: 0.6094\n",
            "Epoch 46/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7251 - loss: 0.5942 - val_accuracy: 0.7450 - val_loss: 0.6087\n",
            "Epoch 47/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6972 - loss: 0.6012 - val_accuracy: 0.7337 - val_loss: 0.6071\n",
            "Epoch 48/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7037 - loss: 0.5964 - val_accuracy: 0.7535 - val_loss: 0.6047\n",
            "Epoch 49/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7007 - loss: 0.5975 - val_accuracy: 0.7082 - val_loss: 0.6039\n",
            "Epoch 50/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7149 - loss: 0.5975 - val_accuracy: 0.7309 - val_loss: 0.6000\n",
            "Epoch 51/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7091 - loss: 0.5915 - val_accuracy: 0.7252 - val_loss: 0.6000\n",
            "Epoch 52/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6821 - loss: 0.5943 - val_accuracy: 0.6997 - val_loss: 0.5983\n",
            "Epoch 53/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5795 - val_accuracy: 0.6941 - val_loss: 0.5977\n",
            "Epoch 54/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7124 - loss: 0.5957 - val_accuracy: 0.7450 - val_loss: 0.5962\n",
            "Epoch 55/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7086 - loss: 0.5754 - val_accuracy: 0.7224 - val_loss: 0.5946\n",
            "Epoch 56/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7323 - loss: 0.5868 - val_accuracy: 0.7479 - val_loss: 0.5946\n",
            "Epoch 57/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7240 - loss: 0.5755 - val_accuracy: 0.6969 - val_loss: 0.5931\n",
            "Epoch 58/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7238 - loss: 0.5854 - val_accuracy: 0.6827 - val_loss: 0.5967\n",
            "Epoch 59/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6979 - loss: 0.5940 - val_accuracy: 0.7450 - val_loss: 0.5936\n",
            "Epoch 60/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7410 - loss: 0.5772 - val_accuracy: 0.7252 - val_loss: 0.5930\n",
            "Epoch 61/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7350 - loss: 0.5797 - val_accuracy: 0.7195 - val_loss: 0.5933\n",
            "Epoch 62/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7486 - loss: 0.5766 - val_accuracy: 0.7082 - val_loss: 0.5932\n",
            "Epoch 63/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7123 - loss: 0.5828 - val_accuracy: 0.7082 - val_loss: 0.5887\n",
            "Epoch 64/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.5726 - val_accuracy: 0.7082 - val_loss: 0.5876\n",
            "Epoch 65/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7017 - loss: 0.6063 - val_accuracy: 0.7224 - val_loss: 0.5896\n",
            "Epoch 66/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7504 - loss: 0.5626 - val_accuracy: 0.7110 - val_loss: 0.5884\n",
            "Epoch 67/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7505 - loss: 0.5698 - val_accuracy: 0.7649 - val_loss: 0.5872\n",
            "Epoch 68/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7349 - loss: 0.5949 - val_accuracy: 0.7167 - val_loss: 0.5863\n",
            "Epoch 69/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7538 - loss: 0.5711 - val_accuracy: 0.7564 - val_loss: 0.5858\n",
            "Epoch 70/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7625 - loss: 0.5672 - val_accuracy: 0.7507 - val_loss: 0.5880\n",
            "Epoch 71/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7265 - loss: 0.5727 - val_accuracy: 0.7309 - val_loss: 0.5896\n",
            "Epoch 72/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7300 - loss: 0.5865 - val_accuracy: 0.6856 - val_loss: 0.5900\n",
            "Epoch 73/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7240 - loss: 0.5817 - val_accuracy: 0.7309 - val_loss: 0.5855\n",
            "Epoch 74/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7614 - loss: 0.5634 - val_accuracy: 0.7337 - val_loss: 0.5826\n",
            "Epoch 75/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7367 - loss: 0.5656 - val_accuracy: 0.7280 - val_loss: 0.5835\n",
            "Epoch 76/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7215 - loss: 0.5767 - val_accuracy: 0.7195 - val_loss: 0.5830\n",
            "Epoch 77/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7560 - loss: 0.5695 - val_accuracy: 0.7649 - val_loss: 0.5816\n",
            "Epoch 78/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7389 - loss: 0.5696 - val_accuracy: 0.7167 - val_loss: 0.5818\n",
            "Epoch 79/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7597 - loss: 0.5599 - val_accuracy: 0.7365 - val_loss: 0.5811\n",
            "Epoch 80/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7576 - loss: 0.5747 - val_accuracy: 0.7620 - val_loss: 0.5802\n",
            "Epoch 81/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7589 - loss: 0.5722 - val_accuracy: 0.7620 - val_loss: 0.5822\n",
            "Epoch 82/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7542 - loss: 0.5733 - val_accuracy: 0.7224 - val_loss: 0.5801\n",
            "Epoch 83/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7510 - loss: 0.5759 - val_accuracy: 0.7195 - val_loss: 0.5793\n",
            "Epoch 84/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7621 - loss: 0.5674 - val_accuracy: 0.7337 - val_loss: 0.5795\n",
            "Epoch 85/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7551 - loss: 0.5735 - val_accuracy: 0.7535 - val_loss: 0.5788\n",
            "Epoch 86/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7595 - loss: 0.5646 - val_accuracy: 0.7337 - val_loss: 0.5790\n",
            "Epoch 87/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7624 - loss: 0.5648 - val_accuracy: 0.7564 - val_loss: 0.5804\n",
            "Epoch 88/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7392 - loss: 0.5600 - val_accuracy: 0.7677 - val_loss: 0.5799\n",
            "Epoch 89/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7638 - loss: 0.5637 - val_accuracy: 0.7649 - val_loss: 0.5770\n",
            "Epoch 90/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7876 - loss: 0.5430 - val_accuracy: 0.7649 - val_loss: 0.5774\n",
            "Epoch 91/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7910 - loss: 0.5559 - val_accuracy: 0.7705 - val_loss: 0.5769\n",
            "Epoch 92/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7570 - loss: 0.5386 - val_accuracy: 0.7167 - val_loss: 0.5775\n",
            "Epoch 93/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7452 - loss: 0.5611 - val_accuracy: 0.7649 - val_loss: 0.5776\n",
            "Epoch 94/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7550 - loss: 0.5688 - val_accuracy: 0.7677 - val_loss: 0.5759\n",
            "Epoch 95/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7881 - loss: 0.5631 - val_accuracy: 0.7705 - val_loss: 0.5752\n",
            "Epoch 96/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7755 - loss: 0.5586 - val_accuracy: 0.6941 - val_loss: 0.5819\n",
            "Epoch 97/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7561 - loss: 0.5491 - val_accuracy: 0.7479 - val_loss: 0.5775\n",
            "Epoch 98/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7451 - loss: 0.5370 - val_accuracy: 0.7677 - val_loss: 0.5746\n",
            "Epoch 99/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.5714 - val_accuracy: 0.7649 - val_loss: 0.5729\n",
            "Epoch 100/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7612 - loss: 0.5624 - val_accuracy: 0.7479 - val_loss: 0.5774\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "Fold 3:\n",
            "Validation Confusion Matrix:\n",
            "[[206  26]\n",
            " [ 57  64]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.89      0.83       232\n",
            "           1       0.71      0.53      0.61       121\n",
            "\n",
            "    accuracy                           0.76       353\n",
            "   macro avg       0.75      0.71      0.72       353\n",
            "weighted avg       0.76      0.76      0.75       353\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.3955 - loss: 5.4853 - val_accuracy: 0.6714 - val_loss: 4.1885\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6441 - loss: 3.8876 - val_accuracy: 0.6714 - val_loss: 3.0096\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6475 - loss: 2.7916 - val_accuracy: 0.6714 - val_loss: 2.1451\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6591 - loss: 1.9848 - val_accuracy: 0.6714 - val_loss: 1.5263\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6701 - loss: 1.4145 - val_accuracy: 0.6714 - val_loss: 1.1262\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6464 - loss: 1.0743 - val_accuracy: 0.6714 - val_loss: 0.9104\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6460 - loss: 0.9016 - val_accuracy: 0.6714 - val_loss: 0.8242\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6704 - loss: 0.8116 - val_accuracy: 0.6714 - val_loss: 0.7813\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6453 - loss: 0.7901 - val_accuracy: 0.6714 - val_loss: 0.7492\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6589 - loss: 0.7521 - val_accuracy: 0.6714 - val_loss: 0.7304\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6761 - loss: 0.7258 - val_accuracy: 0.6714 - val_loss: 0.7187\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6458 - loss: 0.7259 - val_accuracy: 0.6714 - val_loss: 0.6992\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6426 - loss: 0.7166 - val_accuracy: 0.6714 - val_loss: 0.6909\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6513 - loss: 0.7029 - val_accuracy: 0.6714 - val_loss: 0.6807\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6630 - loss: 0.6881 - val_accuracy: 0.6714 - val_loss: 0.6753\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6492 - loss: 0.6894 - val_accuracy: 0.6714 - val_loss: 0.6667\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6576 - loss: 0.6772 - val_accuracy: 0.6714 - val_loss: 0.6631\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6639 - loss: 0.6682 - val_accuracy: 0.6714 - val_loss: 0.6583\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6486 - loss: 0.6721 - val_accuracy: 0.6714 - val_loss: 0.6549\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6519 - loss: 0.6653 - val_accuracy: 0.6714 - val_loss: 0.6507\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6646 - loss: 0.6524 - val_accuracy: 0.6714 - val_loss: 0.6527\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6515 - loss: 0.6585 - val_accuracy: 0.6714 - val_loss: 0.6467\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6443 - loss: 0.6639 - val_accuracy: 0.6714 - val_loss: 0.6400\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6423 - loss: 0.6604 - val_accuracy: 0.6714 - val_loss: 0.6347\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6649 - loss: 0.6372 - val_accuracy: 0.6714 - val_loss: 0.6311\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6517 - loss: 0.6390 - val_accuracy: 0.6714 - val_loss: 0.6253\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6507 - loss: 0.6401 - val_accuracy: 0.6714 - val_loss: 0.6225\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6556 - loss: 0.6353 - val_accuracy: 0.6714 - val_loss: 0.6186\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6628 - loss: 0.6264 - val_accuracy: 0.6714 - val_loss: 0.6159\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6729 - loss: 0.6209 - val_accuracy: 0.7309 - val_loss: 0.6187\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6782 - loss: 0.6272 - val_accuracy: 0.7337 - val_loss: 0.6121\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7083 - loss: 0.6158 - val_accuracy: 0.7734 - val_loss: 0.6133\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6937 - loss: 0.6313 - val_accuracy: 0.7195 - val_loss: 0.6065\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6986 - loss: 0.6129 - val_accuracy: 0.7762 - val_loss: 0.6054\n",
            "Epoch 35/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6939 - loss: 0.6312 - val_accuracy: 0.6714 - val_loss: 0.6117\n",
            "Epoch 36/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6837 - loss: 0.6179 - val_accuracy: 0.7280 - val_loss: 0.5974\n",
            "Epoch 37/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6965 - loss: 0.6021 - val_accuracy: 0.7280 - val_loss: 0.5957\n",
            "Epoch 38/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7102 - loss: 0.5956 - val_accuracy: 0.7790 - val_loss: 0.5959\n",
            "Epoch 39/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7048 - loss: 0.6139 - val_accuracy: 0.6997 - val_loss: 0.5937\n",
            "Epoch 40/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7025 - loss: 0.6057 - val_accuracy: 0.7904 - val_loss: 0.5944\n",
            "Epoch 41/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7469 - loss: 0.5954 - val_accuracy: 0.7535 - val_loss: 0.5899\n",
            "Epoch 42/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7523 - loss: 0.5816 - val_accuracy: 0.6856 - val_loss: 0.5950\n",
            "Epoch 43/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7220 - loss: 0.5874 - val_accuracy: 0.7394 - val_loss: 0.5877\n",
            "Epoch 44/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7052 - loss: 0.6045 - val_accuracy: 0.7394 - val_loss: 0.5862\n",
            "Epoch 45/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7266 - loss: 0.5995 - val_accuracy: 0.7280 - val_loss: 0.5866\n",
            "Epoch 46/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7102 - loss: 0.5936 - val_accuracy: 0.7507 - val_loss: 0.5844\n",
            "Epoch 47/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7117 - loss: 0.6048 - val_accuracy: 0.7450 - val_loss: 0.5838\n",
            "Epoch 48/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7183 - loss: 0.6182 - val_accuracy: 0.8045 - val_loss: 0.5847\n",
            "Epoch 49/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.5908 - val_accuracy: 0.7904 - val_loss: 0.5827\n",
            "Epoch 50/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7115 - loss: 0.5985 - val_accuracy: 0.7989 - val_loss: 0.5832\n",
            "Epoch 51/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7483 - loss: 0.5835 - val_accuracy: 0.7422 - val_loss: 0.5826\n",
            "Epoch 52/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7469 - loss: 0.5967 - val_accuracy: 0.7960 - val_loss: 0.5816\n",
            "Epoch 53/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7387 - loss: 0.5895 - val_accuracy: 0.7989 - val_loss: 0.5825\n",
            "Epoch 54/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7448 - loss: 0.5936 - val_accuracy: 0.8074 - val_loss: 0.5806\n",
            "Epoch 55/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7520 - loss: 0.5930 - val_accuracy: 0.7989 - val_loss: 0.5812\n",
            "Epoch 56/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7587 - loss: 0.5770 - val_accuracy: 0.7960 - val_loss: 0.5819\n",
            "Epoch 57/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7484 - loss: 0.5927 - val_accuracy: 0.7337 - val_loss: 0.5794\n",
            "Epoch 58/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7285 - loss: 0.5821 - val_accuracy: 0.7507 - val_loss: 0.5842\n",
            "Epoch 59/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7510 - loss: 0.5889 - val_accuracy: 0.8102 - val_loss: 0.5774\n",
            "Epoch 60/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.5915 - val_accuracy: 0.7904 - val_loss: 0.5812\n",
            "Epoch 61/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7485 - loss: 0.5949 - val_accuracy: 0.7932 - val_loss: 0.5763\n",
            "Epoch 62/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7761 - loss: 0.5911 - val_accuracy: 0.8130 - val_loss: 0.5755\n",
            "Epoch 63/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7754 - loss: 0.5756 - val_accuracy: 0.8102 - val_loss: 0.5746\n",
            "Epoch 64/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7465 - loss: 0.5882 - val_accuracy: 0.7847 - val_loss: 0.5747\n",
            "Epoch 65/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7588 - loss: 0.5899 - val_accuracy: 0.7535 - val_loss: 0.5739\n",
            "Epoch 66/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7377 - loss: 0.6052 - val_accuracy: 0.7734 - val_loss: 0.5732\n",
            "Epoch 67/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7657 - loss: 0.5700 - val_accuracy: 0.8130 - val_loss: 0.5730\n",
            "Epoch 68/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7769 - loss: 0.5744 - val_accuracy: 0.8130 - val_loss: 0.5729\n",
            "Epoch 69/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7461 - loss: 0.5741 - val_accuracy: 0.7989 - val_loss: 0.5741\n",
            "Epoch 70/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7493 - loss: 0.5794 - val_accuracy: 0.7932 - val_loss: 0.5765\n",
            "Epoch 71/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7554 - loss: 0.5823 - val_accuracy: 0.8074 - val_loss: 0.5731\n",
            "Epoch 72/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7832 - loss: 0.5633 - val_accuracy: 0.8045 - val_loss: 0.5726\n",
            "Epoch 73/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.5906 - val_accuracy: 0.7479 - val_loss: 0.5718\n",
            "Epoch 74/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7490 - loss: 0.5721 - val_accuracy: 0.7394 - val_loss: 0.5810\n",
            "Epoch 75/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7509 - loss: 0.5695 - val_accuracy: 0.8159 - val_loss: 0.5714\n",
            "Epoch 76/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.5807 - val_accuracy: 0.8159 - val_loss: 0.5707\n",
            "Epoch 77/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7549 - loss: 0.5817 - val_accuracy: 0.8017 - val_loss: 0.5725\n",
            "Epoch 78/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7719 - loss: 0.5796 - val_accuracy: 0.7365 - val_loss: 0.5733\n",
            "Epoch 79/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7572 - loss: 0.5616 - val_accuracy: 0.8187 - val_loss: 0.5686\n",
            "Epoch 80/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7657 - loss: 0.5877 - val_accuracy: 0.8244 - val_loss: 0.5685\n",
            "Epoch 81/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7753 - loss: 0.5669 - val_accuracy: 0.8244 - val_loss: 0.5679\n",
            "Epoch 82/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7703 - loss: 0.5743 - val_accuracy: 0.7450 - val_loss: 0.5704\n",
            "Epoch 83/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7369 - loss: 0.5725 - val_accuracy: 0.7280 - val_loss: 0.5797\n",
            "Epoch 84/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7273 - loss: 0.5824 - val_accuracy: 0.7875 - val_loss: 0.5725\n",
            "Epoch 85/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7683 - loss: 0.5891 - val_accuracy: 0.7450 - val_loss: 0.5705\n",
            "Epoch 86/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7346 - loss: 0.5724 - val_accuracy: 0.8187 - val_loss: 0.5660\n",
            "Epoch 87/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7612 - loss: 0.5687 - val_accuracy: 0.8187 - val_loss: 0.5665\n",
            "Epoch 88/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7565 - loss: 0.5833 - val_accuracy: 0.8244 - val_loss: 0.5657\n",
            "Epoch 89/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7450 - loss: 0.5987 - val_accuracy: 0.7904 - val_loss: 0.5712\n",
            "Epoch 90/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7375 - loss: 0.5954 - val_accuracy: 0.7790 - val_loss: 0.5716\n",
            "Epoch 91/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7458 - loss: 0.6018 - val_accuracy: 0.8272 - val_loss: 0.5645\n",
            "Epoch 92/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7782 - loss: 0.5682 - val_accuracy: 0.7649 - val_loss: 0.5651\n",
            "Epoch 93/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7767 - loss: 0.5749 - val_accuracy: 0.8244 - val_loss: 0.5635\n",
            "Epoch 94/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7608 - loss: 0.5550 - val_accuracy: 0.8244 - val_loss: 0.5628\n",
            "Epoch 95/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7588 - loss: 0.5867 - val_accuracy: 0.8102 - val_loss: 0.5646\n",
            "Epoch 96/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.7562 - loss: 0.5809 - val_accuracy: 0.7450 - val_loss: 0.5667\n",
            "Epoch 97/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7466 - loss: 0.5678 - val_accuracy: 0.8300 - val_loss: 0.5621\n",
            "Epoch 98/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7550 - loss: 0.5667 - val_accuracy: 0.7564 - val_loss: 0.5630\n",
            "Epoch 99/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7619 - loss: 0.5758 - val_accuracy: 0.7904 - val_loss: 0.5662\n",
            "Epoch 100/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7734 - loss: 0.5688 - val_accuracy: 0.8074 - val_loss: 0.5624\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Fold 4:\n",
            "Validation Confusion Matrix:\n",
            "[[224  13]\n",
            " [ 47  69]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.95      0.88       237\n",
            "           1       0.84      0.59      0.70       116\n",
            "\n",
            "    accuracy                           0.83       353\n",
            "   macro avg       0.83      0.77      0.79       353\n",
            "weighted avg       0.83      0.83      0.82       353\n",
            "\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6094 - loss: 5.2886 - val_accuracy: 0.6591 - val_loss: 4.1425\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6431 - loss: 3.8512 - val_accuracy: 0.6591 - val_loss: 3.0191\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6462 - loss: 2.7954 - val_accuracy: 0.6591 - val_loss: 2.1763\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6817 - loss: 1.9971 - val_accuracy: 0.6591 - val_loss: 1.5711\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6269 - loss: 1.4693 - val_accuracy: 0.6591 - val_loss: 1.1653\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6384 - loss: 1.1093 - val_accuracy: 0.6591 - val_loss: 0.9491\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6589 - loss: 0.9200 - val_accuracy: 0.6591 - val_loss: 0.8568\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6674 - loss: 0.8363 - val_accuracy: 0.6591 - val_loss: 0.8065\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6548 - loss: 0.7985 - val_accuracy: 0.6591 - val_loss: 0.7773\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6453 - loss: 0.7768 - val_accuracy: 0.6591 - val_loss: 0.7531\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6658 - loss: 0.7438 - val_accuracy: 0.6591 - val_loss: 0.7385\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6463 - loss: 0.7372 - val_accuracy: 0.6591 - val_loss: 0.7232\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6639 - loss: 0.7175 - val_accuracy: 0.6591 - val_loss: 0.7132\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6682 - loss: 0.7027 - val_accuracy: 0.6591 - val_loss: 0.7056\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6623 - loss: 0.7016 - val_accuracy: 0.6591 - val_loss: 0.6961\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6484 - loss: 0.7002 - val_accuracy: 0.6591 - val_loss: 0.6894\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6641 - loss: 0.6855 - val_accuracy: 0.6591 - val_loss: 0.6886\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6609 - loss: 0.6810 - val_accuracy: 0.6591 - val_loss: 0.6749\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6572 - loss: 0.6685 - val_accuracy: 0.6591 - val_loss: 0.6716\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6669 - loss: 0.6646 - val_accuracy: 0.6591 - val_loss: 0.6646\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6547 - loss: 0.6579 - val_accuracy: 0.6591 - val_loss: 0.6558\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6570 - loss: 0.6584 - val_accuracy: 0.6591 - val_loss: 0.6469\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6781 - loss: 0.6303 - val_accuracy: 0.7102 - val_loss: 0.6487\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7063 - loss: 0.6394 - val_accuracy: 0.6619 - val_loss: 0.6384\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6760 - loss: 0.6363 - val_accuracy: 0.6733 - val_loss: 0.6348\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6615 - loss: 0.6381 - val_accuracy: 0.6903 - val_loss: 0.6307\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6844 - loss: 0.6278 - val_accuracy: 0.7045 - val_loss: 0.6289\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6774 - loss: 0.6233 - val_accuracy: 0.6903 - val_loss: 0.6398\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7174 - loss: 0.6239 - val_accuracy: 0.7188 - val_loss: 0.6230\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7106 - loss: 0.6209 - val_accuracy: 0.7102 - val_loss: 0.6201\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6980 - loss: 0.6216 - val_accuracy: 0.7216 - val_loss: 0.6174\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7048 - loss: 0.6187 - val_accuracy: 0.7074 - val_loss: 0.6159\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6948 - loss: 0.6188 - val_accuracy: 0.6847 - val_loss: 0.6157\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7120 - loss: 0.6166 - val_accuracy: 0.7244 - val_loss: 0.6112\n",
            "Epoch 35/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7273 - loss: 0.6125 - val_accuracy: 0.7244 - val_loss: 0.6166\n",
            "Epoch 36/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7374 - loss: 0.6081 - val_accuracy: 0.7045 - val_loss: 0.6070\n",
            "Epoch 37/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7279 - loss: 0.5996 - val_accuracy: 0.7188 - val_loss: 0.6062\n",
            "Epoch 38/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7184 - loss: 0.6003 - val_accuracy: 0.7528 - val_loss: 0.6099\n",
            "Epoch 39/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7120 - loss: 0.6188 - val_accuracy: 0.7386 - val_loss: 0.6069\n",
            "Epoch 40/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6950 - loss: 0.6068 - val_accuracy: 0.7131 - val_loss: 0.5997\n",
            "Epoch 41/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7454 - loss: 0.5799 - val_accuracy: 0.7330 - val_loss: 0.6015\n",
            "Epoch 42/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7025 - loss: 0.6029 - val_accuracy: 0.7330 - val_loss: 0.5983\n",
            "Epoch 43/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7403 - loss: 0.5868 - val_accuracy: 0.7585 - val_loss: 0.5976\n",
            "Epoch 44/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7182 - loss: 0.5864 - val_accuracy: 0.7727 - val_loss: 0.5977\n",
            "Epoch 45/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5902 - val_accuracy: 0.7102 - val_loss: 0.6032\n",
            "Epoch 46/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7391 - loss: 0.5922 - val_accuracy: 0.7330 - val_loss: 0.5944\n",
            "Epoch 47/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7339 - loss: 0.5989 - val_accuracy: 0.7330 - val_loss: 0.5928\n",
            "Epoch 48/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7302 - loss: 0.5997 - val_accuracy: 0.7074 - val_loss: 0.6029\n",
            "Epoch 49/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7172 - loss: 0.6057 - val_accuracy: 0.7102 - val_loss: 0.5888\n",
            "Epoch 50/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7440 - loss: 0.5828 - val_accuracy: 0.7614 - val_loss: 0.5906\n",
            "Epoch 51/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7047 - loss: 0.5958 - val_accuracy: 0.7301 - val_loss: 0.5950\n",
            "Epoch 52/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7468 - loss: 0.5733 - val_accuracy: 0.7756 - val_loss: 0.5888\n",
            "Epoch 53/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7333 - loss: 0.5742 - val_accuracy: 0.7756 - val_loss: 0.5877\n",
            "Epoch 54/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7485 - loss: 0.5828 - val_accuracy: 0.6989 - val_loss: 0.5957\n",
            "Epoch 55/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6950 - loss: 0.5927 - val_accuracy: 0.7585 - val_loss: 0.5888\n",
            "Epoch 56/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7305 - loss: 0.5815 - val_accuracy: 0.7756 - val_loss: 0.5857\n",
            "Epoch 57/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7638 - loss: 0.5688 - val_accuracy: 0.7131 - val_loss: 0.5832\n",
            "Epoch 58/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7327 - loss: 0.5876 - val_accuracy: 0.7784 - val_loss: 0.5842\n",
            "Epoch 59/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7409 - loss: 0.5671 - val_accuracy: 0.7670 - val_loss: 0.5817\n",
            "Epoch 60/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7486 - loss: 0.5651 - val_accuracy: 0.7244 - val_loss: 0.5804\n",
            "Epoch 61/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7502 - loss: 0.5532 - val_accuracy: 0.7756 - val_loss: 0.5825\n",
            "Epoch 62/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7324 - loss: 0.5698 - val_accuracy: 0.7528 - val_loss: 0.5792\n",
            "Epoch 63/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7314 - loss: 0.5757 - val_accuracy: 0.7159 - val_loss: 0.5780\n",
            "Epoch 64/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7470 - loss: 0.5703 - val_accuracy: 0.7784 - val_loss: 0.5780\n",
            "Epoch 65/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7654 - loss: 0.5692 - val_accuracy: 0.7216 - val_loss: 0.5866\n",
            "Epoch 66/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.5814 - val_accuracy: 0.7670 - val_loss: 0.5766\n",
            "Epoch 67/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7504 - loss: 0.5651 - val_accuracy: 0.7273 - val_loss: 0.5797\n",
            "Epoch 68/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7375 - loss: 0.5743 - val_accuracy: 0.7614 - val_loss: 0.5747\n",
            "Epoch 69/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7658 - loss: 0.5778 - val_accuracy: 0.7244 - val_loss: 0.5743\n",
            "Epoch 70/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7581 - loss: 0.5615 - val_accuracy: 0.7841 - val_loss: 0.5749\n",
            "Epoch 71/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7668 - loss: 0.5644 - val_accuracy: 0.7699 - val_loss: 0.5731\n",
            "Epoch 72/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7527 - loss: 0.5713 - val_accuracy: 0.7841 - val_loss: 0.5724\n",
            "Epoch 73/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7622 - loss: 0.5705 - val_accuracy: 0.7756 - val_loss: 0.5719\n",
            "Epoch 74/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7811 - loss: 0.5605 - val_accuracy: 0.7301 - val_loss: 0.5798\n",
            "Epoch 75/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7391 - loss: 0.5751 - val_accuracy: 0.7301 - val_loss: 0.5735\n",
            "Epoch 76/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7300 - loss: 0.5734 - val_accuracy: 0.7841 - val_loss: 0.5728\n",
            "Epoch 77/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7359 - loss: 0.5702 - val_accuracy: 0.7614 - val_loss: 0.5699\n",
            "Epoch 78/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7282 - loss: 0.5616 - val_accuracy: 0.7841 - val_loss: 0.5713\n",
            "Epoch 79/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7496 - loss: 0.5685 - val_accuracy: 0.7841 - val_loss: 0.5693\n",
            "Epoch 80/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7689 - loss: 0.5602 - val_accuracy: 0.7244 - val_loss: 0.5694\n",
            "Epoch 81/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7427 - loss: 0.5684 - val_accuracy: 0.7812 - val_loss: 0.5685\n",
            "Epoch 82/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7783 - loss: 0.5580 - val_accuracy: 0.7301 - val_loss: 0.5691\n",
            "Epoch 83/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7564 - loss: 0.5533 - val_accuracy: 0.7841 - val_loss: 0.5683\n",
            "Epoch 84/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7500 - loss: 0.5595 - val_accuracy: 0.7727 - val_loss: 0.5669\n",
            "Epoch 85/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7676 - loss: 0.5711 - val_accuracy: 0.7756 - val_loss: 0.5668\n",
            "Epoch 86/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7444 - loss: 0.5755 - val_accuracy: 0.7841 - val_loss: 0.5658\n",
            "Epoch 87/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7734 - loss: 0.5582 - val_accuracy: 0.7841 - val_loss: 0.5657\n",
            "Epoch 88/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7727 - loss: 0.5748 - val_accuracy: 0.7301 - val_loss: 0.5659\n",
            "Epoch 89/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7501 - loss: 0.5577 - val_accuracy: 0.7756 - val_loss: 0.5648\n",
            "Epoch 90/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7591 - loss: 0.5462 - val_accuracy: 0.7614 - val_loss: 0.5697\n",
            "Epoch 91/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7778 - loss: 0.5545 - val_accuracy: 0.7869 - val_loss: 0.5637\n",
            "Epoch 92/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7802 - loss: 0.5553 - val_accuracy: 0.7841 - val_loss: 0.5652\n",
            "Epoch 93/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7757 - loss: 0.5396 - val_accuracy: 0.7841 - val_loss: 0.5632\n",
            "Epoch 94/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7749 - loss: 0.5637 - val_accuracy: 0.7244 - val_loss: 0.5686\n",
            "Epoch 95/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7557 - loss: 0.5517 - val_accuracy: 0.7784 - val_loss: 0.5670\n",
            "Epoch 96/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7601 - loss: 0.5672 - val_accuracy: 0.7841 - val_loss: 0.5640\n",
            "Epoch 97/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7881 - loss: 0.5454 - val_accuracy: 0.7898 - val_loss: 0.5612\n",
            "Epoch 98/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7635 - loss: 0.5620 - val_accuracy: 0.7841 - val_loss: 0.5616\n",
            "Epoch 99/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7864 - loss: 0.5389 - val_accuracy: 0.7869 - val_loss: 0.5603\n",
            "Epoch 100/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7778 - loss: 0.5454 - val_accuracy: 0.7670 - val_loss: 0.5607\n",
            "\u001b[1m11/11\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step \n",
            "Fold 5:\n",
            "Validation Confusion Matrix:\n",
            "[[206  26]\n",
            " [ 49  71]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.89      0.85       232\n",
            "           1       0.73      0.59      0.65       120\n",
            "\n",
            "    accuracy                           0.79       352\n",
            "   macro avg       0.77      0.74      0.75       352\n",
            "weighted avg       0.78      0.79      0.78       352\n",
            "\n",
            "Average Accuracy across all folds: 0.7574\n",
            "Average Precision across all folds: 0.7102\n",
            "Epoch 1/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5256 - loss: 5.3236 - val_accuracy: 0.6686 - val_loss: 4.0934\n",
            "Epoch 2/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6541 - loss: 3.7930 - val_accuracy: 0.6686 - val_loss: 2.9290\n",
            "Epoch 3/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6593 - loss: 2.7017 - val_accuracy: 0.6686 - val_loss: 2.0773\n",
            "Epoch 4/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6631 - loss: 1.9096 - val_accuracy: 0.6686 - val_loss: 1.4708\n",
            "Epoch 5/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6730 - loss: 1.3549 - val_accuracy: 0.6686 - val_loss: 1.0870\n",
            "Epoch 6/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6360 - loss: 1.0439 - val_accuracy: 0.6686 - val_loss: 0.8882\n",
            "Epoch 7/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6715 - loss: 0.8654 - val_accuracy: 0.6686 - val_loss: 0.8154\n",
            "Epoch 8/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6552 - loss: 0.8110 - val_accuracy: 0.6686 - val_loss: 0.7709\n",
            "Epoch 9/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6596 - loss: 0.7710 - val_accuracy: 0.6686 - val_loss: 0.7446\n",
            "Epoch 10/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6349 - loss: 0.7622 - val_accuracy: 0.6686 - val_loss: 0.7231\n",
            "Epoch 11/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6306 - loss: 0.7462 - val_accuracy: 0.6686 - val_loss: 0.7059\n",
            "Epoch 12/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6575 - loss: 0.7128 - val_accuracy: 0.6686 - val_loss: 0.6929\n",
            "Epoch 13/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6512 - loss: 0.7028 - val_accuracy: 0.6686 - val_loss: 0.6815\n",
            "Epoch 14/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6409 - loss: 0.6980 - val_accuracy: 0.6686 - val_loss: 0.6701\n",
            "Epoch 15/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6508 - loss: 0.6824 - val_accuracy: 0.6686 - val_loss: 0.6630\n",
            "Epoch 16/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6446 - loss: 0.6785 - val_accuracy: 0.6686 - val_loss: 0.6577\n",
            "Epoch 17/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6339 - loss: 0.6816 - val_accuracy: 0.6686 - val_loss: 0.6537\n",
            "Epoch 18/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6673 - loss: 0.6581 - val_accuracy: 0.6686 - val_loss: 0.6517\n",
            "Epoch 19/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6660 - loss: 0.6563 - val_accuracy: 0.6686 - val_loss: 0.6506\n",
            "Epoch 20/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6318 - loss: 0.6750 - val_accuracy: 0.6686 - val_loss: 0.6466\n",
            "Epoch 21/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6727 - loss: 0.6505 - val_accuracy: 0.6686 - val_loss: 0.6464\n",
            "Epoch 22/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6550 - loss: 0.6571 - val_accuracy: 0.6686 - val_loss: 0.6426\n",
            "Epoch 23/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6583 - loss: 0.6515 - val_accuracy: 0.6686 - val_loss: 0.6417\n",
            "Epoch 24/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6571 - loss: 0.6533 - val_accuracy: 0.6686 - val_loss: 0.6386\n",
            "Epoch 25/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6483 - loss: 0.6548 - val_accuracy: 0.6686 - val_loss: 0.6366\n",
            "Epoch 26/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6713 - loss: 0.6395 - val_accuracy: 0.6686 - val_loss: 0.6358\n",
            "Epoch 27/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6669 - loss: 0.6444 - val_accuracy: 0.6686 - val_loss: 0.6338\n",
            "Epoch 28/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6550 - loss: 0.6443 - val_accuracy: 0.6686 - val_loss: 0.6278\n",
            "Epoch 29/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6520 - loss: 0.6437 - val_accuracy: 0.6686 - val_loss: 0.6244\n",
            "Epoch 30/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6595 - loss: 0.6376 - val_accuracy: 0.6686 - val_loss: 0.6225\n",
            "Epoch 31/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6698 - loss: 0.6229 - val_accuracy: 0.6686 - val_loss: 0.6218\n",
            "Epoch 32/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6574 - loss: 0.6221 - val_accuracy: 0.6686 - val_loss: 0.6162\n",
            "Epoch 33/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6620 - loss: 0.6283 - val_accuracy: 0.6686 - val_loss: 0.6207\n",
            "Epoch 34/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6402 - loss: 0.6324 - val_accuracy: 0.6686 - val_loss: 0.6120\n",
            "Epoch 35/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6686 - loss: 0.6205 - val_accuracy: 0.6686 - val_loss: 0.6104\n",
            "Epoch 36/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6626 - loss: 0.6189 - val_accuracy: 0.6686 - val_loss: 0.6089\n",
            "Epoch 37/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.6651 - loss: 0.6105 - val_accuracy: 0.7195 - val_loss: 0.6092\n",
            "Epoch 38/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6772 - loss: 0.6192 - val_accuracy: 0.6969 - val_loss: 0.6058\n",
            "Epoch 39/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6772 - loss: 0.6267 - val_accuracy: 0.7309 - val_loss: 0.6063\n",
            "Epoch 40/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6935 - loss: 0.6210 - val_accuracy: 0.7167 - val_loss: 0.6031\n",
            "Epoch 41/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6771 - loss: 0.6152 - val_accuracy: 0.7592 - val_loss: 0.6096\n",
            "Epoch 42/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.6928 - loss: 0.6173 - val_accuracy: 0.7167 - val_loss: 0.5995\n",
            "Epoch 43/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6962 - loss: 0.6034 - val_accuracy: 0.7139 - val_loss: 0.6079\n",
            "Epoch 44/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7265 - loss: 0.6106 - val_accuracy: 0.7450 - val_loss: 0.5985\n",
            "Epoch 45/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7224 - loss: 0.5905 - val_accuracy: 0.7252 - val_loss: 0.6005\n",
            "Epoch 46/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7068 - loss: 0.6172 - val_accuracy: 0.7252 - val_loss: 0.5981\n",
            "Epoch 47/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.7050 - loss: 0.6132 - val_accuracy: 0.7224 - val_loss: 0.5980\n",
            "Epoch 48/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7080 - loss: 0.6065 - val_accuracy: 0.7224 - val_loss: 0.5962\n",
            "Epoch 49/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7060 - loss: 0.6143 - val_accuracy: 0.7620 - val_loss: 0.5957\n",
            "Epoch 50/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7040 - loss: 0.6113 - val_accuracy: 0.7507 - val_loss: 0.5937\n",
            "Epoch 51/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7021 - loss: 0.5994 - val_accuracy: 0.7564 - val_loss: 0.5946\n",
            "Epoch 52/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7095 - loss: 0.6015 - val_accuracy: 0.7620 - val_loss: 0.5965\n",
            "Epoch 53/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7019 - loss: 0.6151 - val_accuracy: 0.7479 - val_loss: 0.5933\n",
            "Epoch 54/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7328 - loss: 0.6040 - val_accuracy: 0.7564 - val_loss: 0.5901\n",
            "Epoch 55/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7036 - loss: 0.5927 - val_accuracy: 0.7337 - val_loss: 0.5949\n",
            "Epoch 56/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7230 - loss: 0.5996 - val_accuracy: 0.7394 - val_loss: 0.5899\n",
            "Epoch 57/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7153 - loss: 0.5964 - val_accuracy: 0.7507 - val_loss: 0.5935\n",
            "Epoch 58/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6751 - loss: 0.6068 - val_accuracy: 0.7479 - val_loss: 0.5894\n",
            "Epoch 59/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7142 - loss: 0.6067 - val_accuracy: 0.7450 - val_loss: 0.5899\n",
            "Epoch 60/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7213 - loss: 0.5992 - val_accuracy: 0.7620 - val_loss: 0.5879\n",
            "Epoch 61/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7212 - loss: 0.5903 - val_accuracy: 0.7309 - val_loss: 0.5871\n",
            "Epoch 62/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7242 - loss: 0.5997 - val_accuracy: 0.7450 - val_loss: 0.5867\n",
            "Epoch 63/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7381 - loss: 0.5903 - val_accuracy: 0.7337 - val_loss: 0.5857\n",
            "Epoch 64/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7418 - loss: 0.5821 - val_accuracy: 0.7139 - val_loss: 0.5950\n",
            "Epoch 65/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6956 - loss: 0.5925 - val_accuracy: 0.7365 - val_loss: 0.5870\n",
            "Epoch 66/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7313 - loss: 0.5979 - val_accuracy: 0.7507 - val_loss: 0.5853\n",
            "Epoch 67/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.6073 - val_accuracy: 0.7479 - val_loss: 0.5849\n",
            "Epoch 68/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7271 - loss: 0.5870 - val_accuracy: 0.6912 - val_loss: 0.5918\n",
            "Epoch 69/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6970 - loss: 0.5951 - val_accuracy: 0.7677 - val_loss: 0.5874\n",
            "Epoch 70/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7484 - loss: 0.5924 - val_accuracy: 0.7677 - val_loss: 0.5850\n",
            "Epoch 71/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7293 - loss: 0.5839 - val_accuracy: 0.7535 - val_loss: 0.5870\n",
            "Epoch 72/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7301 - loss: 0.5927 - val_accuracy: 0.7762 - val_loss: 0.5835\n",
            "Epoch 73/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7686 - loss: 0.5755 - val_accuracy: 0.7649 - val_loss: 0.5816\n",
            "Epoch 74/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7374 - loss: 0.5770 - val_accuracy: 0.7025 - val_loss: 0.5887\n",
            "Epoch 75/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7546 - loss: 0.5872 - val_accuracy: 0.7677 - val_loss: 0.5846\n",
            "Epoch 76/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7360 - loss: 0.5880 - val_accuracy: 0.7847 - val_loss: 0.5834\n",
            "Epoch 77/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7306 - loss: 0.6009 - val_accuracy: 0.7564 - val_loss: 0.5811\n",
            "Epoch 78/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7176 - loss: 0.5943 - val_accuracy: 0.7677 - val_loss: 0.5798\n",
            "Epoch 79/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7605 - loss: 0.5703 - val_accuracy: 0.7790 - val_loss: 0.5798\n",
            "Epoch 80/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7571 - loss: 0.5872 - val_accuracy: 0.7790 - val_loss: 0.5816\n",
            "Epoch 81/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7298 - loss: 0.5918 - val_accuracy: 0.7507 - val_loss: 0.5807\n",
            "Epoch 82/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7337 - loss: 0.5700 - val_accuracy: 0.7082 - val_loss: 0.5871\n",
            "Epoch 83/100\n",
            "\u001b[1m45/45\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7558 - loss: 0.5784 - val_accuracy: 0.7762 - val_loss: 0.5816\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
            "\n",
            "Final Model Evaluation on Test Set:\n",
            "Confusion Matrix:\n",
            "[[269  25]\n",
            " [ 81  66]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.77      0.91      0.84       294\n",
            "           1       0.73      0.45      0.55       147\n",
            "\n",
            "    accuracy                           0.76       441\n",
            "   macro avg       0.75      0.68      0.70       441\n",
            "weighted avg       0.75      0.76      0.74       441\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_f13b65f2-041a-4bc8-be91-eac55acb3958\", \"nn_model.pkl\", 61190)"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "neuralnetwork(X,y_stableFlag)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "L3Op78AbbGAo"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNo25IRhDIF7fCwBeSgbNWt",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}